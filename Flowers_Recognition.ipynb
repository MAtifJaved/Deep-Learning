{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Flowers Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aJDWOWPSKcO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjjvZv-zY7TN",
        "outputId": "603c37e0-3d38-4441-94c0-8ae3858e9552"
      },
      "source": [
        "file_name = \"/content/drive/MyDrive/archive2.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXdIfOHlZrQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c03128-4ea4-4538-97ef-b083564dbd95"
      },
      "source": [
        "directory = Path(\"/content/archive2/flowers\")\n",
        "flowers = []\n",
        "features = []\n",
        "labels = []\n",
        "# Iterating Over Directory To Extract Sub Directories\n",
        "for dir in directory.iterdir():\n",
        "  flowers.append(dir.name)\n",
        "  print(dir.name)\n",
        "# Iterating Over Sub Directories To Extract Lables\n",
        "  for imgpath in dir.iterdir():\n",
        "    if imgpath.name.endswith(\"jpg\"):\n",
        "      labels.append(dir.name)\n",
        "      imgarr = cv2.imread(str(imgpath), cv2.IMREAD_GRAYSCALE)\n",
        "      imgarr = cv2.resize(imgarr, (150,150))\n",
        "      features.append(imgarr)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dandelion\n",
            "daisy\n",
            "tulip\n",
            "sunflower\n",
            "rose\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cptn4bo4szah",
        "outputId": "6b81e1cc-8f21-4e9d-da7a-d98f2cc5f1ae"
      },
      "source": [
        "features[0:1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[133, 113, 107, ..., 111, 112, 111],\n",
              "        [134, 115, 108, ..., 112, 113, 112],\n",
              "        [134, 115, 109, ..., 115, 115, 114],\n",
              "        ...,\n",
              "        [113, 107, 114, ...,  45,  43,  44],\n",
              "        [115, 112, 118, ...,  45,  43,  44],\n",
              "        [117, 118, 119, ...,  46,  43,  43]], dtype=uint8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTJ3K8s5hLev",
        "outputId": "487cb9a1-d952-4a25-cdd1-1ffc3b9d5260"
      },
      "source": [
        "flowers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dandelion', 'daisy', 'tulip', 'sunflower', 'rose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtbsKNlh9Ag",
        "outputId": "7a609b2c-6c66-4aa8-d1de-2d0370bca8e4"
      },
      "source": [
        "print(type(flowers))\n",
        "print(type(features))\n",
        "print(type(labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE8dEkF0qvQR",
        "outputId": "e844bd9c-8ada-4d7e-b414-4ac051ea8b6b"
      },
      "source": [
        "# Transform the image array to a numpy type\n",
        "train = np.asarray(features)\n",
        "print(train.shape)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4323, 150, 150)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfXTK_KXkWuL"
      },
      "source": [
        "# Extract the labels\n",
        "\n",
        "label_dummies = pd.get_dummies(labels)\n",
        "\n",
        "labels =  label_dummies.values.argmax(1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmhCPFmMkfOb",
        "outputId": "0bf794ef-e124-4c1e-ecb5-c5fbdfaed277"
      },
      "source": [
        "labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcgY_nGZkkA7",
        "outputId": "678f281c-7954-4b69-f1d4-f92949e08878"
      },
      "source": [
        "pd.unique(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 4, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0qLZvguvB5e",
        "outputId": "443f7179-a492-4f8e-9797-39c98793a43f"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKRIA-GcmFpt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels=train_test_split(train, labels, test_size=0.4, random_state=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l3AW7AOmkxY",
        "outputId": "c7975aa6-1ac2-46e6-912a-ac4799bdc958"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2593, 150, 150)\n",
            "(2593,)\n",
            "(1730, 150, 150)\n",
            "(1730,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amUt_O3Qqvb2"
      },
      "source": [
        "train_images=train_data.reshape((2593,150*150)) # (150*150)= 22500 \n",
        "train_images=train_images.astype('float32') / 255 # Doing Normalization ( To make the data between 0 -> 255 because RGB values alters between 0 to 255)\n",
        "\n",
        "test_images=test_data.reshape((1730,150*150))\n",
        "test_images=test_images.astype('float32') / 255 # Normalization"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnmWDiOz080",
        "outputId": "bdee9d49-3d38-4c3c-c853-e592cfda539e"
      },
      "source": [
        "train_labels[3]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKGkUY4P2bGj",
        "outputId": "a5f3e67b-c2e7-4a3e-b459-f1fe5cdbf767"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2593, 22500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZAqWVRk2dh6",
        "outputId": "f1b91436-7c0b-4dc8-f83d-a9882551fb83"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2593,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIEkH8O4EYI6"
      },
      "source": [
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1cGFqgQElTF",
        "outputId": "5e054c75-6395-4df2-847c-ec9558e71027"
      },
      "source": [
        "train_labels[3]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJlvI9GMk5i3"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "network = models.Sequential()\n",
        "\n",
        "network.add(layers.Dense(512, activation= 'relu', input_shape=(150*150,)))\n",
        "network.add(layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym_gnuDVnZUW"
      },
      "source": [
        "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uXoU5KyneD6",
        "outputId": "250c58a2-74e8-40f4-d8f7-cf220d7c38e4"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=25, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 57.3432 - accuracy: 0.2067\n",
            "Epoch 2/25\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 13.0192 - accuracy: 0.2325\n",
            "Epoch 3/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 9.8800 - accuracy: 0.2413\n",
            "Epoch 4/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 10.9965 - accuracy: 0.2285\n",
            "Epoch 5/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 8.8151 - accuracy: 0.2376\n",
            "Epoch 6/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 8.8510 - accuracy: 0.2542\n",
            "Epoch 7/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 8.9150 - accuracy: 0.2370\n",
            "Epoch 8/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 9.1317 - accuracy: 0.2364\n",
            "Epoch 9/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 6.8228 - accuracy: 0.2538\n",
            "Epoch 10/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 6.6500 - accuracy: 0.2602\n",
            "Epoch 11/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 5.9810 - accuracy: 0.2540\n",
            "Epoch 12/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 4.9726 - accuracy: 0.2729\n",
            "Epoch 13/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 5.3560 - accuracy: 0.2692\n",
            "Epoch 14/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 4.8532 - accuracy: 0.2586\n",
            "Epoch 15/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 4.7896 - accuracy: 0.2716\n",
            "Epoch 16/25\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 4.7897 - accuracy: 0.2589\n",
            "Epoch 17/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 4.0775 - accuracy: 0.2797\n",
            "Epoch 18/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 4.1622 - accuracy: 0.2716\n",
            "Epoch 19/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 4.2876 - accuracy: 0.2565\n",
            "Epoch 20/25\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 3.6683 - accuracy: 0.2690\n",
            "Epoch 21/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 3.7185 - accuracy: 0.2783\n",
            "Epoch 22/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 2.6685 - accuracy: 0.3068\n",
            "Epoch 23/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 3.2098 - accuracy: 0.2778\n",
            "Epoch 24/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 3.6111 - accuracy: 0.2516\n",
            "Epoch 25/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 2.9389 - accuracy: 0.2554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUU8KIjOnqNf"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.02),input_shape=(150*150,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256,kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R_eJR9kFq-j",
        "outputId": "728526e5-2564-4cc4-d0be-6b4acb35fabc"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=25, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 3.0460 - accuracy: 0.2877\n",
            "Epoch 2/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 2.7873 - accuracy: 0.3278\n",
            "Epoch 3/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 2.6632 - accuracy: 0.3047\n",
            "Epoch 4/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 2.6349 - accuracy: 0.3128\n",
            "Epoch 5/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 2.4821 - accuracy: 0.3166\n",
            "Epoch 6/25\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 2.7166 - accuracy: 0.2931\n",
            "Epoch 7/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 2.3772 - accuracy: 0.3197\n",
            "Epoch 8/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 2.3432 - accuracy: 0.3367\n",
            "Epoch 9/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 2.3542 - accuracy: 0.3216\n",
            "Epoch 10/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 2.0728 - accuracy: 0.3378\n",
            "Epoch 11/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 2.0597 - accuracy: 0.3425\n",
            "Epoch 12/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 2.0098 - accuracy: 0.3351\n",
            "Epoch 13/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 2.1408 - accuracy: 0.3193\n",
            "Epoch 14/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.9218 - accuracy: 0.3513\n",
            "Epoch 15/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.7639 - accuracy: 0.3610\n",
            "Epoch 16/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.8356 - accuracy: 0.3490\n",
            "Epoch 17/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.6642 - accuracy: 0.3756\n",
            "Epoch 18/25\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.6435 - accuracy: 0.3714\n",
            "Epoch 19/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.6479 - accuracy: 0.3718\n",
            "Epoch 20/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.6248 - accuracy: 0.3521\n",
            "Epoch 21/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.4801 - accuracy: 0.3857\n",
            "Epoch 22/25\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.4733 - accuracy: 0.3926\n",
            "Epoch 23/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.4321 - accuracy: 0.3957\n",
            "Epoch 24/25\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.4307 - accuracy: 0.4080\n",
            "Epoch 25/25\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.4406 - accuracy: 0.3845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjsYOQV1Fzma"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.02),input_shape=(150*150,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.02) ,activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffqUPCvcGkjA",
        "outputId": "3af1f54d-b7e9-4d88-b186-4d4f28bca23a"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=50, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.4630 - accuracy: 0.4034\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.3816 - accuracy: 0.4161\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.3620 - accuracy: 0.4308\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.3738 - accuracy: 0.4153\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.3623 - accuracy: 0.4261\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.3299 - accuracy: 0.4447\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.3197 - accuracy: 0.4489\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.3152 - accuracy: 0.4292\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.3261 - accuracy: 0.4373\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.3082 - accuracy: 0.4466\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.3116 - accuracy: 0.4543\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.3023 - accuracy: 0.4659\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.2583 - accuracy: 0.4636\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2604 - accuracy: 0.4732\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2580 - accuracy: 0.4821\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.2554 - accuracy: 0.4670\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2673 - accuracy: 0.4774\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 1.2353 - accuracy: 0.4882\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2254 - accuracy: 0.4960\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.2509 - accuracy: 0.4936\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2536 - accuracy: 0.5048\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.1924 - accuracy: 0.5179\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.2248 - accuracy: 0.5006\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.2283 - accuracy: 0.5037\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1508 - accuracy: 0.5160\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.1509 - accuracy: 0.5156\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.2350 - accuracy: 0.5133\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.1594 - accuracy: 0.5133\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.1456 - accuracy: 0.5368\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.1593 - accuracy: 0.5384\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1046 - accuracy: 0.5480\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.1449 - accuracy: 0.5307\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.1175 - accuracy: 0.5534\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.1175 - accuracy: 0.5434\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.1113 - accuracy: 0.5496\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.1071 - accuracy: 0.5611\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.1705 - accuracy: 0.5361\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.0938 - accuracy: 0.5708\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.1607 - accuracy: 0.5611\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.0668 - accuracy: 0.5796\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.0635 - accuracy: 0.5712\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 1.1189 - accuracy: 0.5739\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 4s 185ms/step - loss: 1.0766 - accuracy: 0.5931\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 4s 185ms/step - loss: 1.0291 - accuracy: 0.5812\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.0439 - accuracy: 0.6016\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 4s 185ms/step - loss: 1.0132 - accuracy: 0.5997\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.0251 - accuracy: 0.5839\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 1.0291 - accuracy: 0.6086\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 1.0928 - accuracy: 0.5762\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 1.0417 - accuracy: 0.6001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq4NWQGGGo7F"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qys2E8f5IA9M",
        "outputId": "2d93fade-320e-4df7-84d7-20d99ad49ac6"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=200, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 1.0761 - accuracy: 0.5974\n",
            "Epoch 2/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 1.0537 - accuracy: 0.5931\n",
            "Epoch 3/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.9836 - accuracy: 0.6128\n",
            "Epoch 4/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 1.0085 - accuracy: 0.5989\n",
            "Epoch 5/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.9901 - accuracy: 0.6267\n",
            "Epoch 6/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.9835 - accuracy: 0.6321\n",
            "Epoch 7/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 1.0036 - accuracy: 0.6305\n",
            "Epoch 8/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 1.0172 - accuracy: 0.6140\n",
            "Epoch 9/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.9660 - accuracy: 0.6224\n",
            "Epoch 10/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.9823 - accuracy: 0.6271\n",
            "Epoch 11/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.9453 - accuracy: 0.6410\n",
            "Epoch 12/200\n",
            "41/41 [==============================] - 5s 131ms/step - loss: 0.9942 - accuracy: 0.6340\n",
            "Epoch 13/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.9215 - accuracy: 0.6502\n",
            "Epoch 14/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.9121 - accuracy: 0.6460\n",
            "Epoch 15/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.9597 - accuracy: 0.6521\n",
            "Epoch 16/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8919 - accuracy: 0.6641\n",
            "Epoch 17/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 1.0285 - accuracy: 0.6545\n",
            "Epoch 18/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8566 - accuracy: 0.6691\n",
            "Epoch 19/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.9238 - accuracy: 0.6606\n",
            "Epoch 20/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.9854 - accuracy: 0.6564\n",
            "Epoch 21/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.8237 - accuracy: 0.6903\n",
            "Epoch 22/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8515 - accuracy: 0.6784\n",
            "Epoch 23/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.8619 - accuracy: 0.6818\n",
            "Epoch 24/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.9005 - accuracy: 0.6803\n",
            "Epoch 25/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.8626 - accuracy: 0.6807\n",
            "Epoch 26/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.8635 - accuracy: 0.6776\n",
            "Epoch 27/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.8881 - accuracy: 0.6803\n",
            "Epoch 28/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.8390 - accuracy: 0.6969\n",
            "Epoch 29/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.8272 - accuracy: 0.7050\n",
            "Epoch 30/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.8104 - accuracy: 0.7030\n",
            "Epoch 31/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.9494 - accuracy: 0.6930\n",
            "Epoch 32/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8221 - accuracy: 0.7096\n",
            "Epoch 33/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.8631 - accuracy: 0.6953\n",
            "Epoch 34/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.8305 - accuracy: 0.7003\n",
            "Epoch 35/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8136 - accuracy: 0.7061\n",
            "Epoch 36/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.7983 - accuracy: 0.7015\n",
            "Epoch 37/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.8312 - accuracy: 0.6946\n",
            "Epoch 38/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.7657 - accuracy: 0.7297\n",
            "Epoch 39/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.8373 - accuracy: 0.7196\n",
            "Epoch 40/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.7459 - accuracy: 0.7270\n",
            "Epoch 41/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.8387 - accuracy: 0.7108\n",
            "Epoch 42/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.7372 - accuracy: 0.7339\n",
            "Epoch 43/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.8125 - accuracy: 0.7192\n",
            "Epoch 44/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.7903 - accuracy: 0.7231\n",
            "Epoch 45/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.8113 - accuracy: 0.6934\n",
            "Epoch 46/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.7033 - accuracy: 0.7401\n",
            "Epoch 47/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.7951 - accuracy: 0.7123\n",
            "Epoch 48/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.6708 - accuracy: 0.7702\n",
            "Epoch 49/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.8090 - accuracy: 0.7339\n",
            "Epoch 50/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.7088 - accuracy: 0.7343\n",
            "Epoch 51/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.7498 - accuracy: 0.7293\n",
            "Epoch 52/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.7723 - accuracy: 0.7389\n",
            "Epoch 53/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.7408 - accuracy: 0.7447\n",
            "Epoch 54/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.7281 - accuracy: 0.7273\n",
            "Epoch 55/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.8486 - accuracy: 0.7354\n",
            "Epoch 56/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.6545 - accuracy: 0.7675\n",
            "Epoch 57/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6708 - accuracy: 0.7597\n",
            "Epoch 58/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.6976 - accuracy: 0.7451\n",
            "Epoch 59/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.6559 - accuracy: 0.7655\n",
            "Epoch 60/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.7571 - accuracy: 0.7594\n",
            "Epoch 61/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.8272 - accuracy: 0.7547\n",
            "Epoch 62/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.7130 - accuracy: 0.7628\n",
            "Epoch 63/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.6237 - accuracy: 0.7890\n",
            "Epoch 64/200\n",
            "41/41 [==============================] - 6s 142ms/step - loss: 0.7052 - accuracy: 0.7578\n",
            "Epoch 65/200\n",
            "41/41 [==============================] - 6s 143ms/step - loss: 0.6309 - accuracy: 0.7790\n",
            "Epoch 66/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.7026 - accuracy: 0.7752\n",
            "Epoch 67/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6820 - accuracy: 0.7821\n",
            "Epoch 68/200\n",
            "41/41 [==============================] - 6s 142ms/step - loss: 0.6370 - accuracy: 0.7582\n",
            "Epoch 69/200\n",
            "41/41 [==============================] - 6s 143ms/step - loss: 0.6772 - accuracy: 0.7632\n",
            "Epoch 70/200\n",
            "41/41 [==============================] - 6s 143ms/step - loss: 0.6669 - accuracy: 0.7694\n",
            "Epoch 71/200\n",
            "41/41 [==============================] - 6s 143ms/step - loss: 0.6144 - accuracy: 0.7902\n",
            "Epoch 72/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.6210 - accuracy: 0.7732\n",
            "Epoch 73/200\n",
            "41/41 [==============================] - 6s 142ms/step - loss: 0.6192 - accuracy: 0.7782\n",
            "Epoch 74/200\n",
            "41/41 [==============================] - 6s 143ms/step - loss: 0.6775 - accuracy: 0.7840\n",
            "Epoch 75/200\n",
            "41/41 [==============================] - 6s 144ms/step - loss: 0.6338 - accuracy: 0.7887\n",
            "Epoch 76/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.7466 - accuracy: 0.7621\n",
            "Epoch 77/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.5968 - accuracy: 0.7991\n",
            "Epoch 78/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.6362 - accuracy: 0.7748\n",
            "Epoch 79/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.6250 - accuracy: 0.7906\n",
            "Epoch 80/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.6250 - accuracy: 0.7937\n",
            "Epoch 81/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6458 - accuracy: 0.7759\n",
            "Epoch 82/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5787 - accuracy: 0.7921\n",
            "Epoch 83/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.7613 - accuracy: 0.7524\n",
            "Epoch 84/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5533 - accuracy: 0.8160\n",
            "Epoch 85/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.6493 - accuracy: 0.7825\n",
            "Epoch 86/200\n",
            "41/41 [==============================] - 6s 142ms/step - loss: 0.5749 - accuracy: 0.8018\n",
            "Epoch 87/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.6954 - accuracy: 0.7833\n",
            "Epoch 88/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5656 - accuracy: 0.8145\n",
            "Epoch 89/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5624 - accuracy: 0.8141\n",
            "Epoch 90/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5892 - accuracy: 0.7871\n",
            "Epoch 91/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6591 - accuracy: 0.7817\n",
            "Epoch 92/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5481 - accuracy: 0.8218\n",
            "Epoch 93/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.6013 - accuracy: 0.8187\n",
            "Epoch 94/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.7006 - accuracy: 0.7944\n",
            "Epoch 95/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6560 - accuracy: 0.7998\n",
            "Epoch 96/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5092 - accuracy: 0.8195\n",
            "Epoch 97/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5818 - accuracy: 0.8033\n",
            "Epoch 98/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.6059 - accuracy: 0.8068\n",
            "Epoch 99/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.5107 - accuracy: 0.8168\n",
            "Epoch 100/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.5705 - accuracy: 0.8211\n",
            "Epoch 101/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6452 - accuracy: 0.8010\n",
            "Epoch 102/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.5276 - accuracy: 0.8241\n",
            "Epoch 103/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.5383 - accuracy: 0.8241\n",
            "Epoch 104/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.5420 - accuracy: 0.8160\n",
            "Epoch 105/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.6349 - accuracy: 0.8222\n",
            "Epoch 106/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5194 - accuracy: 0.8349\n",
            "Epoch 107/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5473 - accuracy: 0.8253\n",
            "Epoch 108/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.6453 - accuracy: 0.8103\n",
            "Epoch 109/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.5158 - accuracy: 0.8176\n",
            "Epoch 110/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5663 - accuracy: 0.8241\n",
            "Epoch 111/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.6297 - accuracy: 0.8357\n",
            "Epoch 112/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.4369 - accuracy: 0.8461\n",
            "Epoch 113/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5727 - accuracy: 0.8284\n",
            "Epoch 114/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.6170 - accuracy: 0.8122\n",
            "Epoch 115/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.7727 - accuracy: 0.8272\n",
            "Epoch 116/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.4658 - accuracy: 0.8384\n",
            "Epoch 117/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5181 - accuracy: 0.8280\n",
            "Epoch 118/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.4897 - accuracy: 0.8307\n",
            "Epoch 119/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5669 - accuracy: 0.8257\n",
            "Epoch 120/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5171 - accuracy: 0.8276\n",
            "Epoch 121/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.7049 - accuracy: 0.8292\n",
            "Epoch 122/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.6168 - accuracy: 0.8461\n",
            "Epoch 123/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.4976 - accuracy: 0.8392\n",
            "Epoch 124/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5275 - accuracy: 0.8403\n",
            "Epoch 125/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.4407 - accuracy: 0.8496\n",
            "Epoch 126/200\n",
            "41/41 [==============================] - 6s 140ms/step - loss: 0.5152 - accuracy: 0.8299\n",
            "Epoch 127/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5914 - accuracy: 0.8423\n",
            "Epoch 128/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.7031 - accuracy: 0.8430\n",
            "Epoch 129/200\n",
            "41/41 [==============================] - 6s 145ms/step - loss: 0.5876 - accuracy: 0.8118\n",
            "Epoch 130/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.4291 - accuracy: 0.8492\n",
            "Epoch 131/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.6497 - accuracy: 0.8180\n",
            "Epoch 132/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.4293 - accuracy: 0.8677\n",
            "Epoch 133/200\n",
            "41/41 [==============================] - 6s 141ms/step - loss: 0.6688 - accuracy: 0.8311\n",
            "Epoch 134/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.3992 - accuracy: 0.8639\n",
            "Epoch 135/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.7094 - accuracy: 0.8492\n",
            "Epoch 136/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.5112 - accuracy: 0.8349\n",
            "Epoch 137/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4792 - accuracy: 0.8427\n",
            "Epoch 138/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4993 - accuracy: 0.8627\n",
            "Epoch 139/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.4961 - accuracy: 0.8581\n",
            "Epoch 140/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5993 - accuracy: 0.8523\n",
            "Epoch 141/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.4246 - accuracy: 0.8735\n",
            "Epoch 142/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.5950 - accuracy: 0.8550\n",
            "Epoch 143/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.6625 - accuracy: 0.8342\n",
            "Epoch 144/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5489 - accuracy: 0.8187\n",
            "Epoch 145/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.5877 - accuracy: 0.8565\n",
            "Epoch 146/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.3652 - accuracy: 0.8754\n",
            "Epoch 147/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.6407 - accuracy: 0.8438\n",
            "Epoch 148/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5411 - accuracy: 0.8388\n",
            "Epoch 149/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.4055 - accuracy: 0.8716\n",
            "Epoch 150/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.8267 - accuracy: 0.8423\n",
            "Epoch 151/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4578 - accuracy: 0.8797\n",
            "Epoch 152/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4707 - accuracy: 0.8554\n",
            "Epoch 153/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.3963 - accuracy: 0.8754\n",
            "Epoch 154/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5427 - accuracy: 0.8646\n",
            "Epoch 155/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.4677 - accuracy: 0.8700\n",
            "Epoch 156/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.8291 - accuracy: 0.8195\n",
            "Epoch 157/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.3267 - accuracy: 0.8905\n",
            "Epoch 158/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.4776 - accuracy: 0.8546\n",
            "Epoch 159/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.3928 - accuracy: 0.8735\n",
            "Epoch 160/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.5240 - accuracy: 0.8585\n",
            "Epoch 161/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.3982 - accuracy: 0.8812\n",
            "Epoch 162/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4233 - accuracy: 0.8835\n",
            "Epoch 163/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.4933 - accuracy: 0.8616\n",
            "Epoch 164/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.3939 - accuracy: 0.8727\n",
            "Epoch 165/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.5881 - accuracy: 0.8492\n",
            "Epoch 166/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.5064 - accuracy: 0.8585\n",
            "Epoch 167/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 1.0886 - accuracy: 0.8392\n",
            "Epoch 168/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.4488 - accuracy: 0.8723\n",
            "Epoch 169/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.3894 - accuracy: 0.8789\n",
            "Epoch 170/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.3769 - accuracy: 0.8789\n",
            "Epoch 171/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.4533 - accuracy: 0.8793\n",
            "Epoch 172/200\n",
            "41/41 [==============================] - 6s 137ms/step - loss: 0.7620 - accuracy: 0.8384\n",
            "Epoch 173/200\n",
            "41/41 [==============================] - 6s 136ms/step - loss: 0.3295 - accuracy: 0.8924\n",
            "Epoch 174/200\n",
            "41/41 [==============================] - 6s 138ms/step - loss: 0.4592 - accuracy: 0.8616\n",
            "Epoch 175/200\n",
            "41/41 [==============================] - 6s 139ms/step - loss: 0.4294 - accuracy: 0.8866\n",
            "Epoch 176/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.5569 - accuracy: 0.8747\n",
            "Epoch 177/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.7054 - accuracy: 0.8469\n",
            "Epoch 178/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.3606 - accuracy: 0.8893\n",
            "Epoch 179/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.4560 - accuracy: 0.8704\n",
            "Epoch 180/200\n",
            "41/41 [==============================] - 5s 132ms/step - loss: 0.4094 - accuracy: 0.8947\n",
            "Epoch 181/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.5403 - accuracy: 0.8546\n",
            "Epoch 182/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.5836 - accuracy: 0.8743\n",
            "Epoch 183/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.2972 - accuracy: 0.9128\n",
            "Epoch 184/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.4008 - accuracy: 0.8870\n",
            "Epoch 185/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.6530 - accuracy: 0.8531\n",
            "Epoch 186/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.3599 - accuracy: 0.8943\n",
            "Epoch 187/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.4951 - accuracy: 0.8820\n",
            "Epoch 188/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.4902 - accuracy: 0.8889\n",
            "Epoch 189/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.4551 - accuracy: 0.8685\n",
            "Epoch 190/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.5285 - accuracy: 0.8804\n",
            "Epoch 191/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.3495 - accuracy: 0.8889\n",
            "Epoch 192/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.6630 - accuracy: 0.8943\n",
            "Epoch 193/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.2781 - accuracy: 0.8997\n",
            "Epoch 194/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.4759 - accuracy: 0.8693\n",
            "Epoch 195/200\n",
            "41/41 [==============================] - 6s 134ms/step - loss: 0.3306 - accuracy: 0.9063\n",
            "Epoch 196/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.4725 - accuracy: 0.8766\n",
            "Epoch 197/200\n",
            "41/41 [==============================] - 5s 134ms/step - loss: 0.4206 - accuracy: 0.8743\n",
            "Epoch 198/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.4725 - accuracy: 0.8882\n",
            "Epoch 199/200\n",
            "41/41 [==============================] - 5s 133ms/step - loss: 0.3762 - accuracy: 0.8828\n",
            "Epoch 200/200\n",
            "41/41 [==============================] - 6s 135ms/step - loss: 0.3842 - accuracy: 0.8997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m66VyZEeLkta",
        "outputId": "87ddc34b-5618-4104-f36a-01b7d864ff18"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 3s 42ms/step - loss: 1.7189 - accuracy: 0.1641\n",
            "test accuracy is : 0.1710982620716095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnamwGoSICoM"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='tanh',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='tanh'))\n",
        "model.add(layers.Dense(256, activation='tanh'))\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "model.add(layers.Dense(64, activation='tanh'))\n",
        "model.add(layers.Dense(32, activation='tanh'))\n",
        "model.add(layers.Dense(16, activation='tanh'))\n",
        "model.add(layers.Dense(8, activation='tanh'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnEJjHVMJChr",
        "outputId": "b03abae8-3ca4-485f-ca69-13b16ac5f1c0"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=100, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.7428 - accuracy: 0.8515\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1419 - accuracy: 0.9545\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2742 - accuracy: 0.8986\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.7609 - accuracy: 0.8631\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1186 - accuracy: 0.9595\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.6728 - accuracy: 0.8700\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2026 - accuracy: 0.9310\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.2752 - accuracy: 0.9155\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.5359 - accuracy: 0.8939\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3401 - accuracy: 0.8816\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.7240 - accuracy: 0.8604\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.1473 - accuracy: 0.9530\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2531 - accuracy: 0.9140\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.3526 - accuracy: 0.8959\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.5749 - accuracy: 0.8712\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2823 - accuracy: 0.9082\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2445 - accuracy: 0.9375\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.5402 - accuracy: 0.8693\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4647 - accuracy: 0.8785\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1832 - accuracy: 0.9445\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2957 - accuracy: 0.9109\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.3112 - accuracy: 0.8993\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3242 - accuracy: 0.9163\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.9896 - accuracy: 0.8438\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.1157 - accuracy: 0.9595\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.4265 - accuracy: 0.8874\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.3032 - accuracy: 0.8982\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.1857 - accuracy: 0.9379\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.7330 - accuracy: 0.9051\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2456 - accuracy: 0.9148\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.6699 - accuracy: 0.8720\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3148 - accuracy: 0.9009\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4054 - accuracy: 0.9017\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4329 - accuracy: 0.9013\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1510 - accuracy: 0.9456\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2403 - accuracy: 0.9279\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.7238 - accuracy: 0.8627\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1138 - accuracy: 0.9614\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.0449 - accuracy: 0.8608\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.1290 - accuracy: 0.9553\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.5211 - accuracy: 0.8889\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2149 - accuracy: 0.9213\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.4909 - accuracy: 0.8812\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.3891 - accuracy: 0.9040\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1097 - accuracy: 0.9637\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.5536 - accuracy: 0.8970\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.2867 - accuracy: 0.9005\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.2705 - accuracy: 0.9140\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.3382 - accuracy: 0.9190\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1966 - accuracy: 0.9391\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.7712 - accuracy: 0.8804\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1225 - accuracy: 0.9618\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.2883 - accuracy: 0.9202\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.5231 - accuracy: 0.8774\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.2804 - accuracy: 0.9175\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.4862 - accuracy: 0.8804\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.1009 - accuracy: 0.9688\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.4055 - accuracy: 0.9071\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2703 - accuracy: 0.9167\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.4729 - accuracy: 0.9028\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.5451 - accuracy: 0.8673\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.1589 - accuracy: 0.9607\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 0.4182 - accuracy: 0.8966\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.2396 - accuracy: 0.9371\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.5060 - accuracy: 0.8750\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.0914 - accuracy: 0.9722\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.6685 - accuracy: 0.8824\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2038 - accuracy: 0.9371\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.4371 - accuracy: 0.9040\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.3225 - accuracy: 0.8430\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.0966 - accuracy: 0.9684\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.4125 - accuracy: 0.9036\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.0927 - accuracy: 0.9691\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.6719 - accuracy: 0.8685\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.6693 - accuracy: 0.8897\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.2258 - accuracy: 0.9329\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.3186 - accuracy: 0.9036\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.2594 - accuracy: 0.9148\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 0.4808 - accuracy: 0.8858\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 4s 187ms/step - loss: 0.1128 - accuracy: 0.9634\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 0.3156 - accuracy: 0.9152\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 2.0984 - accuracy: 0.8334\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 0.2033 - accuracy: 0.9360\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 0.1187 - accuracy: 0.9626\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.3035 - accuracy: 0.9202\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 0.4069 - accuracy: 0.8862\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.6353 - accuracy: 0.9198\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 4s 184ms/step - loss: 0.2739 - accuracy: 0.9464\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.4475 - accuracy: 0.9051\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.0935 - accuracy: 0.9680\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 0.5096 - accuracy: 0.8966\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.1947 - accuracy: 0.9398\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.6703 - accuracy: 0.9082\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.2402 - accuracy: 0.9163\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 0.5330 - accuracy: 0.9063\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 4s 183ms/step - loss: 0.1952 - accuracy: 0.9549\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.4907 - accuracy: 0.9071\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0830 - accuracy: 0.9757\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.4980 - accuracy: 0.8905\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.1135 - accuracy: 0.9603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeG_HQSUMyRp",
        "outputId": "88ca2980-625e-485a-e3ce-5e927c7a5219"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 3s 43ms/step - loss: 1.6961 - accuracy: 0.1688\n",
            "test accuracy is : 0.17225433886051178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJe4nI8tOQ6u"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeyu8XH3Ol90",
        "outputId": "3602e63e-3c85-44fc-f386-8fecf2be064a"
      },
      "source": [
        "history = network.fit(train_images, train_labels, epochs=100, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.3871 - accuracy: 0.9047\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1804 - accuracy: 0.9464\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.4397 - accuracy: 0.8847\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3459 - accuracy: 0.9136\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.2307 - accuracy: 0.9329\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.5581 - accuracy: 0.8858\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0651 - accuracy: 0.9807\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.8616 - accuracy: 0.8596\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0782 - accuracy: 0.9749\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.7403 - accuracy: 0.8723\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.0956 - accuracy: 0.9703\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.3530 - accuracy: 0.9217\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3972 - accuracy: 0.9175\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.6055 - accuracy: 0.9001\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.1989 - accuracy: 0.9495\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.2574 - accuracy: 0.9279\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1391 - accuracy: 0.9526\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 1.5576 - accuracy: 0.8238\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.0631 - accuracy: 0.9807\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3293 - accuracy: 0.9175\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4189 - accuracy: 0.9082\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.1017 - accuracy: 0.9703\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 1.0673 - accuracy: 0.8558\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1086 - accuracy: 0.9645\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2413 - accuracy: 0.9352\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.5495 - accuracy: 0.9051\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.4973 - accuracy: 0.8966\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.0589 - accuracy: 0.9838\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.6504 - accuracy: 0.9121\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.2259 - accuracy: 0.9379\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4408 - accuracy: 0.9067\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.0697 - accuracy: 0.9803\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.6106 - accuracy: 0.8990\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2447 - accuracy: 0.9337\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.5845 - accuracy: 0.8808\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.0666 - accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3361 - accuracy: 0.9271\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2102 - accuracy: 0.9333\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.6594 - accuracy: 0.8862\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.1358 - accuracy: 0.9533\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.4901 - accuracy: 0.9059\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.3575 - accuracy: 0.9217\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 0.0992 - accuracy: 0.9653\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.4334 - accuracy: 0.9244\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.7509 - accuracy: 0.9032\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.0639 - accuracy: 0.9807\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.4625 - accuracy: 0.9202\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.9272 - accuracy: 0.8770\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0669 - accuracy: 0.9765\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.0764 - accuracy: 0.9761\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 1.4106 - accuracy: 0.8608\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.0896 - accuracy: 0.9726\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.4008 - accuracy: 0.9321\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.4030 - accuracy: 0.9337\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2526 - accuracy: 0.9371\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.6593 - accuracy: 0.8851\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.0583 - accuracy: 0.9838\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 1.0434 - accuracy: 0.8739\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0601 - accuracy: 0.9811\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.0116 - accuracy: 0.8839\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.4086 - accuracy: 0.9298\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.1121 - accuracy: 0.9661\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.9876 - accuracy: 0.8774\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.0883 - accuracy: 0.9722\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.5076 - accuracy: 0.9194\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.0527 - accuracy: 0.9846\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.7104 - accuracy: 0.9055\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3475 - accuracy: 0.9329\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0513 - accuracy: 0.9853\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 1.6086 - accuracy: 0.8519\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.0440 - accuracy: 0.9880\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.3718 - accuracy: 0.9190\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.0739 - accuracy: 0.9742\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 1.6234 - accuracy: 0.8554\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 4s 175ms/step - loss: 0.0939 - accuracy: 0.9680\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 4s 173ms/step - loss: 0.6067 - accuracy: 0.9032\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 4s 174ms/step - loss: 0.0518 - accuracy: 0.9850\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.3204 - accuracy: 0.9186\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.8200 - accuracy: 0.9113\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.0460 - accuracy: 0.9869\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.5918 - accuracy: 0.8982\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.0709 - accuracy: 0.9753\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.3809 - accuracy: 0.9028\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1664 - accuracy: 0.9522\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 4s 176ms/step - loss: 0.5385 - accuracy: 0.9275\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.5573 - accuracy: 0.8774\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.2023 - accuracy: 0.9468\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.0722 - accuracy: 0.9769\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.7149 - accuracy: 0.9063\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2811 - accuracy: 0.9256\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.0956 - accuracy: 0.9730\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.5487 - accuracy: 0.9387\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.7500 - accuracy: 0.8951\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 4s 181ms/step - loss: 0.0407 - accuracy: 0.9873\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 4s 182ms/step - loss: 0.4756 - accuracy: 0.9024\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.4436 - accuracy: 0.9287\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.4445 - accuracy: 0.9267\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.2579 - accuracy: 0.9587\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 4s 179ms/step - loss: 0.1169 - accuracy: 0.9637\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 4s 180ms/step - loss: 0.5325 - accuracy: 0.9101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzIh7JkvOqul",
        "outputId": "25a34490-e5a7-449b-845f-c70576b50e3b"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 2s 42ms/step - loss: 1.7132 - accuracy: 0.2116\n",
            "test accuracy is : 0.2115606963634491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO-jQYSdQb6C"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(1024, activation='relu',input_shape=(150*150,)))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(32, activation='relu'))\n",
        "  model.add(layers.Dense(16, activation='relu'))\n",
        "  model.add(layers.Dense(8, activation='relu'))\n",
        "  model.add(layers.Dense(5, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WmkB5SlQPJp",
        "outputId": "8d8f8a6c-665a-4450-da2b-3a13fb71791a"
      },
      "source": [
        "k=4\n",
        "num_val_samples = len(train_images) // k\n",
        "num_epochs = 200\n",
        "all_val_accuracy = []\n",
        "for i in range(k):\n",
        "  print(\"Processing Fold #\", i)\n",
        "  val_data = train_images[i * num_val_samples : (i+1) * num_val_samples]\n",
        "  val_targets = train_labels[i * num_val_samples : (i+1) * num_val_samples]\n",
        "  partial_train_data = np.concatenate([train_images[:i * num_val_samples], train_images[(i+1) * num_val_samples:]],axis=0)\n",
        "  partial_train_targets = np.concatenate([train_labels[:i * num_val_samples], train_labels[(i+1) * num_val_samples:]],axis=0)\n",
        "  model = build_model()\n",
        "  history = model.fit(partial_train_data, partial_train_targets, validation_data = (val_data,val_targets),epochs = num_epochs, batch_size = 128, verbose = 1)\n",
        "  val_acc_history = history.history['val_accuracy']\n",
        "  all_val_accuracy.append(val_acc_history) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Fold # 0\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 342ms/step - loss: 3.0523 - accuracy: 0.2232 - val_loss: 1.6084 - val_accuracy: 0.2160\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6085 - accuracy: 0.2260 - val_loss: 1.6076 - val_accuracy: 0.2160\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6079 - accuracy: 0.2268 - val_loss: 1.6069 - val_accuracy: 0.2515\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6065 - accuracy: 0.2375 - val_loss: 1.6061 - val_accuracy: 0.2515\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6063 - accuracy: 0.2427 - val_loss: 1.6055 - val_accuracy: 0.2515\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6059 - accuracy: 0.2211 - val_loss: 1.6049 - val_accuracy: 0.2515\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6053 - accuracy: 0.2408 - val_loss: 1.6044 - val_accuracy: 0.2515\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6059 - accuracy: 0.2237 - val_loss: 1.6039 - val_accuracy: 0.2515\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6044 - accuracy: 0.2304 - val_loss: 1.6035 - val_accuracy: 0.2515\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6040 - accuracy: 0.2414 - val_loss: 1.6031 - val_accuracy: 0.2515\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6038 - accuracy: 0.2363 - val_loss: 1.6028 - val_accuracy: 0.2515\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6041 - accuracy: 0.2345 - val_loss: 1.6026 - val_accuracy: 0.2515\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6041 - accuracy: 0.2241 - val_loss: 1.6024 - val_accuracy: 0.2515\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6042 - accuracy: 0.2233 - val_loss: 1.6021 - val_accuracy: 0.2515\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6043 - accuracy: 0.2351 - val_loss: 1.6018 - val_accuracy: 0.2515\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6034 - accuracy: 0.2320 - val_loss: 1.6016 - val_accuracy: 0.2515\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6013 - accuracy: 0.2305 - val_loss: 1.6013 - val_accuracy: 0.2515\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6037 - accuracy: 0.2290 - val_loss: 1.6012 - val_accuracy: 0.2515\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6029 - accuracy: 0.2344 - val_loss: 1.6011 - val_accuracy: 0.2515\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6023 - accuracy: 0.2264 - val_loss: 1.6010 - val_accuracy: 0.2515\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6026 - accuracy: 0.2363 - val_loss: 1.6008 - val_accuracy: 0.2515\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6028 - accuracy: 0.2343 - val_loss: 1.6007 - val_accuracy: 0.2515\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6049 - accuracy: 0.2314 - val_loss: 1.6006 - val_accuracy: 0.2515\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6025 - accuracy: 0.2317 - val_loss: 1.6006 - val_accuracy: 0.2515\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6035 - accuracy: 0.2343 - val_loss: 1.6005 - val_accuracy: 0.2515\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6029 - accuracy: 0.2287 - val_loss: 1.6005 - val_accuracy: 0.2515\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6018 - accuracy: 0.2279 - val_loss: 1.6005 - val_accuracy: 0.2515\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6027 - accuracy: 0.2306 - val_loss: 1.6004 - val_accuracy: 0.2515\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6010 - accuracy: 0.2393 - val_loss: 1.6003 - val_accuracy: 0.2515\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6015 - accuracy: 0.2362 - val_loss: 1.6002 - val_accuracy: 0.2515\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6025 - accuracy: 0.2344 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5974 - accuracy: 0.2397 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6007 - accuracy: 0.2210 - val_loss: 1.6002 - val_accuracy: 0.2515\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6065 - accuracy: 0.2063 - val_loss: 1.6002 - val_accuracy: 0.2515\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6022 - accuracy: 0.2436 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6011 - accuracy: 0.2300 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6010 - accuracy: 0.2298 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6041 - accuracy: 0.2213 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5976 - accuracy: 0.2546 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6063 - accuracy: 0.2247 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5979 - accuracy: 0.2363 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6022 - accuracy: 0.2304 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6013 - accuracy: 0.2317 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5981 - accuracy: 0.2461 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6029 - accuracy: 0.2295 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6017 - accuracy: 0.2395 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6022 - accuracy: 0.2304 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6032 - accuracy: 0.2224 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 338ms/step - loss: 1.6007 - accuracy: 0.2376 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6020 - accuracy: 0.2344 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6026 - accuracy: 0.2386 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6024 - accuracy: 0.2349 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6023 - accuracy: 0.2327 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5993 - accuracy: 0.2339 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6021 - accuracy: 0.2364 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6018 - accuracy: 0.2213 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.5979 - accuracy: 0.2293 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6004 - accuracy: 0.2307 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6026 - accuracy: 0.2331 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6061 - accuracy: 0.2158 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6036 - accuracy: 0.2352 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6034 - accuracy: 0.2297 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6002 - accuracy: 0.2312 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6011 - accuracy: 0.2141 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5995 - accuracy: 0.2487 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6035 - accuracy: 0.2329 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6011 - accuracy: 0.2248 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6004 - accuracy: 0.2341 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6012 - accuracy: 0.2285 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6026 - accuracy: 0.2312 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6008 - accuracy: 0.2406 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6006 - accuracy: 0.2415 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6006 - accuracy: 0.2410 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6007 - accuracy: 0.2331 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6023 - accuracy: 0.2323 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6017 - accuracy: 0.2322 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6003 - accuracy: 0.2371 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6012 - accuracy: 0.2263 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6006 - accuracy: 0.2323 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6045 - accuracy: 0.2203 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6025 - accuracy: 0.2345 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5977 - accuracy: 0.2293 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6024 - accuracy: 0.2215 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6037 - accuracy: 0.2236 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6055 - accuracy: 0.2240 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6049 - accuracy: 0.2171 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6035 - accuracy: 0.2288 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6033 - accuracy: 0.2298 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6046 - accuracy: 0.2254 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6017 - accuracy: 0.2378 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6022 - accuracy: 0.2401 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6031 - accuracy: 0.2250 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6050 - accuracy: 0.2167 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6027 - accuracy: 0.2323 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6016 - accuracy: 0.2303 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6025 - accuracy: 0.2395 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5998 - accuracy: 0.2250 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6032 - accuracy: 0.2359 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5996 - accuracy: 0.2381 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6033 - accuracy: 0.2248 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6017 - accuracy: 0.2325 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5998 - accuracy: 0.2281 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5995 - accuracy: 0.2479 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5994 - accuracy: 0.2480 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6047 - accuracy: 0.2237 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6043 - accuracy: 0.2268 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6001 - accuracy: 0.2349 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5995 - accuracy: 0.2328 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6019 - accuracy: 0.2341 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5979 - accuracy: 0.2374 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6036 - accuracy: 0.2248 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6020 - accuracy: 0.2239 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6000 - accuracy: 0.2378 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5993 - accuracy: 0.2369 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6034 - accuracy: 0.2228 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6010 - accuracy: 0.2271 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5978 - accuracy: 0.2453 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5993 - accuracy: 0.2384 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5984 - accuracy: 0.2370 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5960 - accuracy: 0.2434 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6023 - accuracy: 0.2346 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6014 - accuracy: 0.2296 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6023 - accuracy: 0.2266 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5997 - accuracy: 0.2406 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6032 - accuracy: 0.2256 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6045 - accuracy: 0.2213 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6029 - accuracy: 0.2248 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6025 - accuracy: 0.2335 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6000 - accuracy: 0.2327 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5982 - accuracy: 0.2431 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6025 - accuracy: 0.2266 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5999 - accuracy: 0.2376 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5996 - accuracy: 0.2335 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6006 - accuracy: 0.2334 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6012 - accuracy: 0.2402 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5989 - accuracy: 0.2509 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6008 - accuracy: 0.2266 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6052 - accuracy: 0.2221 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6074 - accuracy: 0.2199 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6041 - accuracy: 0.2209 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6017 - accuracy: 0.2233 - val_loss: 1.5996 - val_accuracy: 0.2515\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6010 - accuracy: 0.2300 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6008 - accuracy: 0.2331 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6026 - accuracy: 0.2256 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.5999 - accuracy: 0.2425 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6007 - accuracy: 0.2337 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6042 - accuracy: 0.2348 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6011 - accuracy: 0.2375 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6008 - accuracy: 0.2369 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6050 - accuracy: 0.2230 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5996 - accuracy: 0.2326 - val_loss: 1.5997 - val_accuracy: 0.2515\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6046 - accuracy: 0.2226 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6003 - accuracy: 0.2333 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6024 - accuracy: 0.2156 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6020 - accuracy: 0.2354 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5988 - accuracy: 0.2375 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6034 - accuracy: 0.2367 - val_loss: 1.5998 - val_accuracy: 0.2515\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6006 - accuracy: 0.2377 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6050 - accuracy: 0.2274 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5959 - accuracy: 0.2402 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6025 - accuracy: 0.2173 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6001 - accuracy: 0.2471 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.5996 - accuracy: 0.2310 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6039 - accuracy: 0.2239 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6002 - accuracy: 0.2410 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6008 - accuracy: 0.2361 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 311ms/step - loss: 1.6059 - accuracy: 0.2092 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6029 - accuracy: 0.2326 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5990 - accuracy: 0.2282 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6004 - accuracy: 0.2362 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6003 - accuracy: 0.2414 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6020 - accuracy: 0.2336 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 312ms/step - loss: 1.6004 - accuracy: 0.2242 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6052 - accuracy: 0.2293 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5980 - accuracy: 0.2422 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6051 - accuracy: 0.2250 - val_loss: 1.6001 - val_accuracy: 0.2515\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6002 - accuracy: 0.2395 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6042 - accuracy: 0.2370 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6023 - accuracy: 0.2345 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6025 - accuracy: 0.2413 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6008 - accuracy: 0.2376 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6009 - accuracy: 0.2377 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.5986 - accuracy: 0.2387 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6034 - accuracy: 0.2245 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6013 - accuracy: 0.2286 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.5997 - accuracy: 0.2380 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6058 - accuracy: 0.2246 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6024 - accuracy: 0.2277 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6028 - accuracy: 0.2386 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5993 - accuracy: 0.2376 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6009 - accuracy: 0.2269 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6070 - accuracy: 0.2261 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6021 - accuracy: 0.2228 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6028 - accuracy: 0.2453 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6010 - accuracy: 0.2349 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6026 - accuracy: 0.2341 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6007 - accuracy: 0.2369 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6024 - accuracy: 0.2269 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5998 - accuracy: 0.2424 - val_loss: 1.5999 - val_accuracy: 0.2515\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5994 - accuracy: 0.2325 - val_loss: 1.6000 - val_accuracy: 0.2515\n",
            "Processing Fold # 1\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 329ms/step - loss: 2.5742 - accuracy: 0.1946 - val_loss: 1.6093 - val_accuracy: 0.2145\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6248 - accuracy: 0.2091 - val_loss: 1.5949 - val_accuracy: 0.2531\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6391 - accuracy: 0.2171 - val_loss: 1.6656 - val_accuracy: 0.2377\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6133 - accuracy: 0.2130 - val_loss: 1.6158 - val_accuracy: 0.1991\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6127 - accuracy: 0.2101 - val_loss: 1.5825 - val_accuracy: 0.2762\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5903 - accuracy: 0.2456 - val_loss: 1.5768 - val_accuracy: 0.2701\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5950 - accuracy: 0.2568 - val_loss: 1.6074 - val_accuracy: 0.2176\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6083 - accuracy: 0.2319 - val_loss: 1.6081 - val_accuracy: 0.2145\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6064 - accuracy: 0.2272 - val_loss: 1.6036 - val_accuracy: 0.2253\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6042 - accuracy: 0.2534 - val_loss: 1.6075 - val_accuracy: 0.2145\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6059 - accuracy: 0.2265 - val_loss: 1.6073 - val_accuracy: 0.2145\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6057 - accuracy: 0.2259 - val_loss: 1.6063 - val_accuracy: 0.2160\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6057 - accuracy: 0.2122 - val_loss: 1.6034 - val_accuracy: 0.2222\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5939 - accuracy: 0.2524 - val_loss: 1.6008 - val_accuracy: 0.2361\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5967 - accuracy: 0.2533 - val_loss: 1.6015 - val_accuracy: 0.2253\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6135 - accuracy: 0.2394 - val_loss: 1.5854 - val_accuracy: 0.2515\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6015 - accuracy: 0.2422 - val_loss: 1.6064 - val_accuracy: 0.2145\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6042 - accuracy: 0.2293 - val_loss: 1.6062 - val_accuracy: 0.2145\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6026 - accuracy: 0.2313 - val_loss: 1.6060 - val_accuracy: 0.2145\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6027 - accuracy: 0.2344 - val_loss: 1.6057 - val_accuracy: 0.2145\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6002 - accuracy: 0.2368 - val_loss: 1.6055 - val_accuracy: 0.2145\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6036 - accuracy: 0.2252 - val_loss: 1.6054 - val_accuracy: 0.2145\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6039 - accuracy: 0.2187 - val_loss: 1.6052 - val_accuracy: 0.2145\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5990 - accuracy: 0.2490 - val_loss: 1.6051 - val_accuracy: 0.2145\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6019 - accuracy: 0.2373 - val_loss: 1.6050 - val_accuracy: 0.2145\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6015 - accuracy: 0.2229 - val_loss: 1.6048 - val_accuracy: 0.2145\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5994 - accuracy: 0.2308 - val_loss: 1.6047 - val_accuracy: 0.2145\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6027 - accuracy: 0.2197 - val_loss: 1.6046 - val_accuracy: 0.2145\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5997 - accuracy: 0.2362 - val_loss: 1.6045 - val_accuracy: 0.2145\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6051 - accuracy: 0.2177 - val_loss: 1.6044 - val_accuracy: 0.2145\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6007 - accuracy: 0.2226 - val_loss: 1.6043 - val_accuracy: 0.2145\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6045 - accuracy: 0.2203 - val_loss: 1.6043 - val_accuracy: 0.2377\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6020 - accuracy: 0.2288 - val_loss: 1.6043 - val_accuracy: 0.2377\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6010 - accuracy: 0.2373 - val_loss: 1.6042 - val_accuracy: 0.2377\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6008 - accuracy: 0.2395 - val_loss: 1.6041 - val_accuracy: 0.2377\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6016 - accuracy: 0.2368 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6016 - accuracy: 0.2247 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 313ms/step - loss: 1.6000 - accuracy: 0.2354 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.5960 - accuracy: 0.2377 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 315ms/step - loss: 1.6048 - accuracy: 0.2231 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6003 - accuracy: 0.2351 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5953 - accuracy: 0.2494 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6024 - accuracy: 0.2289 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5975 - accuracy: 0.2485 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 314ms/step - loss: 1.6014 - accuracy: 0.2451 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5989 - accuracy: 0.2464 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6038 - accuracy: 0.2364 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6003 - accuracy: 0.2412 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6008 - accuracy: 0.2398 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5991 - accuracy: 0.2469 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6015 - accuracy: 0.2383 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5968 - accuracy: 0.2604 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6015 - accuracy: 0.2384 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5996 - accuracy: 0.2477 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6011 - accuracy: 0.2334 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6010 - accuracy: 0.2369 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5986 - accuracy: 0.2362 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.6032 - accuracy: 0.2273 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6001 - accuracy: 0.2352 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6008 - accuracy: 0.2366 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5993 - accuracy: 0.2380 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6020 - accuracy: 0.2398 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6014 - accuracy: 0.2358 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6029 - accuracy: 0.2208 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6014 - accuracy: 0.2418 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6029 - accuracy: 0.2339 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5985 - accuracy: 0.2350 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6024 - accuracy: 0.2291 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5998 - accuracy: 0.2337 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5980 - accuracy: 0.2450 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6019 - accuracy: 0.2351 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6008 - accuracy: 0.2308 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6044 - accuracy: 0.2187 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5951 - accuracy: 0.2499 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5995 - accuracy: 0.2377 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5944 - accuracy: 0.2531 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5968 - accuracy: 0.2422 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.5994 - accuracy: 0.2378 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6041 - accuracy: 0.2240 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6007 - accuracy: 0.2346 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5991 - accuracy: 0.2425 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5987 - accuracy: 0.2391 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6048 - accuracy: 0.2332 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6042 - accuracy: 0.2297 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6004 - accuracy: 0.2336 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5983 - accuracy: 0.2410 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5946 - accuracy: 0.2568 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6013 - accuracy: 0.2300 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5996 - accuracy: 0.2324 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5984 - accuracy: 0.2354 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5978 - accuracy: 0.2453 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6023 - accuracy: 0.2218 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5993 - accuracy: 0.2475 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6046 - accuracy: 0.2279 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5971 - accuracy: 0.2390 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6012 - accuracy: 0.2431 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6006 - accuracy: 0.2314 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6015 - accuracy: 0.2374 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6005 - accuracy: 0.2408 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6040 - accuracy: 0.2243 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5985 - accuracy: 0.2452 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6015 - accuracy: 0.2312 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6050 - accuracy: 0.2359 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6006 - accuracy: 0.2347 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5992 - accuracy: 0.2457 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6006 - accuracy: 0.2392 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.5980 - accuracy: 0.2394 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6012 - accuracy: 0.2375 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5982 - accuracy: 0.2455 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6035 - accuracy: 0.2377 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5959 - accuracy: 0.2433 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6029 - accuracy: 0.2388 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6027 - accuracy: 0.2352 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5983 - accuracy: 0.2451 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6026 - accuracy: 0.2310 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6011 - accuracy: 0.2290 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6036 - accuracy: 0.2307 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5976 - accuracy: 0.2400 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6004 - accuracy: 0.2478 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6020 - accuracy: 0.2335 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6044 - accuracy: 0.2390 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.5978 - accuracy: 0.2462 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5985 - accuracy: 0.2469 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6018 - accuracy: 0.2419 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6016 - accuracy: 0.2288 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6022 - accuracy: 0.2329 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6003 - accuracy: 0.2342 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5961 - accuracy: 0.2401 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5991 - accuracy: 0.2304 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6022 - accuracy: 0.2361 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6036 - accuracy: 0.2394 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5957 - accuracy: 0.2411 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5999 - accuracy: 0.2400 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6050 - accuracy: 0.2287 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.5971 - accuracy: 0.2466 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6029 - accuracy: 0.2281 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5965 - accuracy: 0.2444 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5977 - accuracy: 0.2440 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6043 - accuracy: 0.2325 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6002 - accuracy: 0.2376 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5989 - accuracy: 0.2383 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5988 - accuracy: 0.2358 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5984 - accuracy: 0.2409 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6044 - accuracy: 0.2251 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5988 - accuracy: 0.2461 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5996 - accuracy: 0.2356 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6023 - accuracy: 0.2393 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6012 - accuracy: 0.2392 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6023 - accuracy: 0.2347 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6022 - accuracy: 0.2439 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6039 - accuracy: 0.2296 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6010 - accuracy: 0.2331 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6026 - accuracy: 0.2272 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5962 - accuracy: 0.2363 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5967 - accuracy: 0.2407 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5980 - accuracy: 0.2472 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5992 - accuracy: 0.2398 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6034 - accuracy: 0.2371 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6024 - accuracy: 0.2398 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5956 - accuracy: 0.2454 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6016 - accuracy: 0.2240 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5981 - accuracy: 0.2438 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6004 - accuracy: 0.2330 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5978 - accuracy: 0.2398 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6038 - accuracy: 0.2218 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5972 - accuracy: 0.2486 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5998 - accuracy: 0.2299 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5994 - accuracy: 0.2448 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.5959 - accuracy: 0.2471 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.6037 - accuracy: 0.2302 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6027 - accuracy: 0.2304 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 317ms/step - loss: 1.6014 - accuracy: 0.2309 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.5997 - accuracy: 0.2427 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.6006 - accuracy: 0.2345 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 316ms/step - loss: 1.5989 - accuracy: 0.2392 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.6022 - accuracy: 0.2365 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6040 - accuracy: 0.2261 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6018 - accuracy: 0.2342 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6031 - accuracy: 0.2280 - val_loss: 1.6036 - val_accuracy: 0.2377\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6014 - accuracy: 0.2293 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5993 - accuracy: 0.2421 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6022 - accuracy: 0.2385 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6015 - accuracy: 0.2353 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6034 - accuracy: 0.2324 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6019 - accuracy: 0.2309 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6010 - accuracy: 0.2291 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5944 - accuracy: 0.2452 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.5996 - accuracy: 0.2366 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6015 - accuracy: 0.2335 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6014 - accuracy: 0.2320 - val_loss: 1.6037 - val_accuracy: 0.2377\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5973 - accuracy: 0.2419 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6014 - accuracy: 0.2335 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5967 - accuracy: 0.2462 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6012 - accuracy: 0.2282 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6025 - accuracy: 0.2277 - val_loss: 1.6038 - val_accuracy: 0.2377\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6000 - accuracy: 0.2394 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6007 - accuracy: 0.2329 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.5996 - accuracy: 0.2386 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5985 - accuracy: 0.2355 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6002 - accuracy: 0.2379 - val_loss: 1.6039 - val_accuracy: 0.2377\n",
            "Processing Fold # 2\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 341ms/step - loss: 2.4246 - accuracy: 0.2163 - val_loss: 1.8692 - val_accuracy: 0.2207\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.8025 - accuracy: 0.2485 - val_loss: 1.7576 - val_accuracy: 0.2207\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.7738 - accuracy: 0.2309 - val_loss: 1.6880 - val_accuracy: 0.1944\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6440 - accuracy: 0.2314 - val_loss: 1.6035 - val_accuracy: 0.2114\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5975 - accuracy: 0.2432 - val_loss: 1.5914 - val_accuracy: 0.2068\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5873 - accuracy: 0.2551 - val_loss: 1.5752 - val_accuracy: 0.2099\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5579 - accuracy: 0.2388 - val_loss: 1.5742 - val_accuracy: 0.2037\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5681 - accuracy: 0.2159 - val_loss: 1.5818 - val_accuracy: 0.2068\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5538 - accuracy: 0.2481 - val_loss: 1.5839 - val_accuracy: 0.2083\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5437 - accuracy: 0.2398 - val_loss: 1.5977 - val_accuracy: 0.2238\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5569 - accuracy: 0.2393 - val_loss: 1.5627 - val_accuracy: 0.2083\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.5333 - accuracy: 0.2413 - val_loss: 1.5721 - val_accuracy: 0.2022\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5419 - accuracy: 0.2301 - val_loss: 1.5852 - val_accuracy: 0.2546\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5334 - accuracy: 0.2882 - val_loss: 1.5701 - val_accuracy: 0.2485\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5231 - accuracy: 0.2750 - val_loss: 1.5665 - val_accuracy: 0.2253\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5216 - accuracy: 0.2613 - val_loss: 1.5773 - val_accuracy: 0.2485\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5442 - accuracy: 0.3026 - val_loss: 1.5664 - val_accuracy: 0.2623\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5094 - accuracy: 0.3114 - val_loss: 1.5566 - val_accuracy: 0.2593\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.5032 - accuracy: 0.3204 - val_loss: 1.5819 - val_accuracy: 0.2593\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.4942 - accuracy: 0.2967 - val_loss: 1.5629 - val_accuracy: 0.2608\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5016 - accuracy: 0.3045 - val_loss: 1.5785 - val_accuracy: 0.2917\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.5028 - accuracy: 0.3214 - val_loss: 1.5858 - val_accuracy: 0.2855\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.5237 - accuracy: 0.3279 - val_loss: 1.5827 - val_accuracy: 0.2886\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.4760 - accuracy: 0.3300 - val_loss: 1.6467 - val_accuracy: 0.2562\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.4876 - accuracy: 0.3294 - val_loss: 1.5811 - val_accuracy: 0.2870\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.4573 - accuracy: 0.3524 - val_loss: 1.6174 - val_accuracy: 0.2623\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.4655 - accuracy: 0.3433 - val_loss: 1.6025 - val_accuracy: 0.2778\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.4394 - accuracy: 0.3842 - val_loss: 1.6330 - val_accuracy: 0.2886\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.4520 - accuracy: 0.3411 - val_loss: 1.6339 - val_accuracy: 0.2793\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.4334 - accuracy: 0.3837 - val_loss: 1.7365 - val_accuracy: 0.2593\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5442 - accuracy: 0.2994 - val_loss: 1.5931 - val_accuracy: 0.2793\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.4428 - accuracy: 0.3651 - val_loss: 1.6149 - val_accuracy: 0.2963\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.4337 - accuracy: 0.3797 - val_loss: 1.8016 - val_accuracy: 0.2608\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.4890 - accuracy: 0.3110 - val_loss: 1.5945 - val_accuracy: 0.2917\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.3783 - accuracy: 0.3940 - val_loss: 2.4949 - val_accuracy: 0.2006\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.7514 - accuracy: 0.2521 - val_loss: 1.7434 - val_accuracy: 0.2269\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6241 - accuracy: 0.2668 - val_loss: 1.6181 - val_accuracy: 0.2485\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.5594 - accuracy: 0.2874 - val_loss: 1.5770 - val_accuracy: 0.2917\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.5152 - accuracy: 0.3350 - val_loss: 1.6422 - val_accuracy: 0.2948\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.4434 - accuracy: 0.3775 - val_loss: 1.7155 - val_accuracy: 0.2315\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.5050 - accuracy: 0.3097 - val_loss: 1.7240 - val_accuracy: 0.2685\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.4799 - accuracy: 0.3342 - val_loss: 1.7765 - val_accuracy: 0.2747\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.4655 - accuracy: 0.3737 - val_loss: 1.6265 - val_accuracy: 0.2917\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.3930 - accuracy: 0.3867 - val_loss: 1.7145 - val_accuracy: 0.2747\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.3865 - accuracy: 0.4014 - val_loss: 1.7010 - val_accuracy: 0.2809\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.3897 - accuracy: 0.3975 - val_loss: 1.6911 - val_accuracy: 0.2870\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 1.3410 - accuracy: 0.4066 - val_loss: 1.6487 - val_accuracy: 0.2793\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.3276 - accuracy: 0.4139 - val_loss: 1.7750 - val_accuracy: 0.2762\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.4250 - accuracy: 0.3792 - val_loss: 1.6574 - val_accuracy: 0.2855\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.3167 - accuracy: 0.4196 - val_loss: 1.8122 - val_accuracy: 0.2855\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.3020 - accuracy: 0.4184 - val_loss: 1.8965 - val_accuracy: 0.2701\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.2970 - accuracy: 0.4375 - val_loss: 1.9166 - val_accuracy: 0.2562\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.2972 - accuracy: 0.4201 - val_loss: 1.8186 - val_accuracy: 0.2870\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.2643 - accuracy: 0.4478 - val_loss: 1.7928 - val_accuracy: 0.2593\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.4418 - accuracy: 0.3640 - val_loss: 1.7684 - val_accuracy: 0.2855\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.2576 - accuracy: 0.4468 - val_loss: 1.8945 - val_accuracy: 0.2639\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.3695 - accuracy: 0.4136 - val_loss: 1.6267 - val_accuracy: 0.2747\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.3894 - accuracy: 0.3881 - val_loss: 1.6477 - val_accuracy: 0.2639\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.3713 - accuracy: 0.4006 - val_loss: 1.7164 - val_accuracy: 0.2731\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.2374 - accuracy: 0.4700 - val_loss: 2.2614 - val_accuracy: 0.2654\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.3760 - accuracy: 0.4200 - val_loss: 1.8963 - val_accuracy: 0.2778\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.2292 - accuracy: 0.4783 - val_loss: 1.8887 - val_accuracy: 0.2809\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1898 - accuracy: 0.4848 - val_loss: 1.9955 - val_accuracy: 0.2731\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1468 - accuracy: 0.4857 - val_loss: 2.1761 - val_accuracy: 0.2778\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.1272 - accuracy: 0.5166 - val_loss: 2.4820 - val_accuracy: 0.2685\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.2346 - accuracy: 0.4521 - val_loss: 2.3011 - val_accuracy: 0.2608\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.2143 - accuracy: 0.4649 - val_loss: 2.1031 - val_accuracy: 0.2500\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.1371 - accuracy: 0.5032 - val_loss: 2.1104 - val_accuracy: 0.2731\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.1823 - accuracy: 0.4920 - val_loss: 2.2744 - val_accuracy: 0.2778\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.1205 - accuracy: 0.5217 - val_loss: 2.3256 - val_accuracy: 0.2639\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.1429 - accuracy: 0.4932 - val_loss: 1.9868 - val_accuracy: 0.2639\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.4185 - accuracy: 0.3696 - val_loss: 1.7522 - val_accuracy: 0.2654\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.1932 - accuracy: 0.4899 - val_loss: 2.0411 - val_accuracy: 0.2778\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0923 - accuracy: 0.5228 - val_loss: 3.1569 - val_accuracy: 0.2654\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.2247 - accuracy: 0.4926 - val_loss: 2.5319 - val_accuracy: 0.2546\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.1280 - accuracy: 0.5118 - val_loss: 2.1317 - val_accuracy: 0.2762\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.1006 - accuracy: 0.5254 - val_loss: 2.1091 - val_accuracy: 0.2731\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.0977 - accuracy: 0.5265 - val_loss: 2.1771 - val_accuracy: 0.2793\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.1573 - accuracy: 0.4847 - val_loss: 2.5074 - val_accuracy: 0.2716\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.0774 - accuracy: 0.5219 - val_loss: 2.4775 - val_accuracy: 0.2685\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0641 - accuracy: 0.5365 - val_loss: 2.6770 - val_accuracy: 0.2809\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.0582 - accuracy: 0.5475 - val_loss: 2.0360 - val_accuracy: 0.2500\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.4590 - accuracy: 0.3499 - val_loss: 1.9614 - val_accuracy: 0.2778\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.2124 - accuracy: 0.4742 - val_loss: 1.9211 - val_accuracy: 0.2747\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.1158 - accuracy: 0.5247 - val_loss: 1.9881 - val_accuracy: 0.2562\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.4433 - accuracy: 0.3544 - val_loss: 2.1132 - val_accuracy: 0.2762\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.4162 - accuracy: 0.3817 - val_loss: 1.9983 - val_accuracy: 0.2716\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1273 - accuracy: 0.5162 - val_loss: 2.3996 - val_accuracy: 0.2469\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0827 - accuracy: 0.5191 - val_loss: 2.8554 - val_accuracy: 0.2670\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.0375 - accuracy: 0.5427 - val_loss: 2.5237 - val_accuracy: 0.2685\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.0920 - accuracy: 0.5297 - val_loss: 2.9653 - val_accuracy: 0.2562\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.0603 - accuracy: 0.5474 - val_loss: 2.4473 - val_accuracy: 0.2870\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.9587 - accuracy: 0.5720 - val_loss: 2.9967 - val_accuracy: 0.2701\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.9264 - accuracy: 0.5879 - val_loss: 3.2471 - val_accuracy: 0.2701\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.9434 - accuracy: 0.5735 - val_loss: 3.8346 - val_accuracy: 0.2485\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.9461 - accuracy: 0.5843 - val_loss: 3.5739 - val_accuracy: 0.2562\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9063 - accuracy: 0.5884 - val_loss: 4.2670 - val_accuracy: 0.2515\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.1740 - accuracy: 0.4846 - val_loss: 2.8502 - val_accuracy: 0.2531\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.0089 - accuracy: 0.5696 - val_loss: 2.4693 - val_accuracy: 0.2747\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 1.1051 - accuracy: 0.5121 - val_loss: 2.5768 - val_accuracy: 0.2840\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9632 - accuracy: 0.5733 - val_loss: 2.5169 - val_accuracy: 0.2670\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.1926 - accuracy: 0.4957 - val_loss: 2.5634 - val_accuracy: 0.2701\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9964 - accuracy: 0.5689 - val_loss: 2.6306 - val_accuracy: 0.2731\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9184 - accuracy: 0.6104 - val_loss: 2.9288 - val_accuracy: 0.2654\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.8964 - accuracy: 0.5974 - val_loss: 2.9921 - val_accuracy: 0.2747\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.8409 - accuracy: 0.6296 - val_loss: 2.8324 - val_accuracy: 0.2701\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.8866 - accuracy: 0.6015 - val_loss: 3.8161 - val_accuracy: 0.2639\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.9481 - accuracy: 0.5811 - val_loss: 3.9286 - val_accuracy: 0.2423\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.1971 - accuracy: 0.5141 - val_loss: 3.1244 - val_accuracy: 0.2577\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.9826 - accuracy: 0.5747 - val_loss: 3.3568 - val_accuracy: 0.2623\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.9768 - accuracy: 0.5718 - val_loss: 3.3427 - val_accuracy: 0.2469\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.9951 - accuracy: 0.5653 - val_loss: 2.9419 - val_accuracy: 0.2531\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.8989 - accuracy: 0.6017 - val_loss: 2.9161 - val_accuracy: 0.2593\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.8355 - accuracy: 0.6277 - val_loss: 3.3097 - val_accuracy: 0.2562\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7905 - accuracy: 0.6505 - val_loss: 3.6203 - val_accuracy: 0.2685\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.7778 - accuracy: 0.6498 - val_loss: 3.3300 - val_accuracy: 0.2654\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.8290 - accuracy: 0.6437 - val_loss: 4.0437 - val_accuracy: 0.2330\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.9227 - accuracy: 0.5958 - val_loss: 3.5003 - val_accuracy: 0.2670\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7910 - accuracy: 0.6432 - val_loss: 4.8252 - val_accuracy: 0.2469\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 1.0606 - accuracy: 0.5605 - val_loss: 2.9815 - val_accuracy: 0.2407\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.9208 - accuracy: 0.6116 - val_loss: 2.9753 - val_accuracy: 0.2685\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.9079 - accuracy: 0.5879 - val_loss: 3.2455 - val_accuracy: 0.2886\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.8218 - accuracy: 0.6522 - val_loss: 3.2583 - val_accuracy: 0.2685\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.7573 - accuracy: 0.6836 - val_loss: 4.3478 - val_accuracy: 0.2515\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7878 - accuracy: 0.6519 - val_loss: 3.2890 - val_accuracy: 0.2747\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.7363 - accuracy: 0.6927 - val_loss: 4.5016 - val_accuracy: 0.2685\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7525 - accuracy: 0.6646 - val_loss: 4.4701 - val_accuracy: 0.2593\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.6708 - accuracy: 0.7039 - val_loss: 4.0128 - val_accuracy: 0.2531\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.7483 - accuracy: 0.6790 - val_loss: 4.0466 - val_accuracy: 0.2731\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.7099 - accuracy: 0.6935 - val_loss: 3.6464 - val_accuracy: 0.2901\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.1641 - accuracy: 0.5501 - val_loss: 2.3497 - val_accuracy: 0.2608\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9558 - accuracy: 0.6022 - val_loss: 3.2819 - val_accuracy: 0.2577\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.7836 - accuracy: 0.6780 - val_loss: 4.1540 - val_accuracy: 0.2500\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.7517 - accuracy: 0.6907 - val_loss: 4.9766 - val_accuracy: 0.2531\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.9640 - accuracy: 0.5867 - val_loss: 3.0986 - val_accuracy: 0.2623\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.7485 - accuracy: 0.6848 - val_loss: 3.8520 - val_accuracy: 0.2623\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.7030 - accuracy: 0.7063 - val_loss: 5.0200 - val_accuracy: 0.2593\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.7602 - accuracy: 0.6705 - val_loss: 4.3593 - val_accuracy: 0.2654\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7257 - accuracy: 0.6803 - val_loss: 4.1021 - val_accuracy: 0.2716\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.7523 - accuracy: 0.6669 - val_loss: 3.5902 - val_accuracy: 0.2731\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.6847 - accuracy: 0.7053 - val_loss: 3.9333 - val_accuracy: 0.2670\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.6420 - accuracy: 0.7390 - val_loss: 4.1207 - val_accuracy: 0.2855\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.7434 - accuracy: 0.6965 - val_loss: 4.6280 - val_accuracy: 0.2608\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.6869 - accuracy: 0.6876 - val_loss: 4.2848 - val_accuracy: 0.2577\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.6460 - accuracy: 0.7127 - val_loss: 4.3964 - val_accuracy: 0.2546\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.6335 - accuracy: 0.7270 - val_loss: 4.8955 - val_accuracy: 0.2654\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.6566 - accuracy: 0.7130 - val_loss: 5.5397 - val_accuracy: 0.2562\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.6227 - accuracy: 0.7378 - val_loss: 4.5428 - val_accuracy: 0.2716\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.6437 - accuracy: 0.7197 - val_loss: 5.3129 - val_accuracy: 0.2593\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.9728 - accuracy: 0.6247 - val_loss: 3.2986 - val_accuracy: 0.2407\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.7626 - accuracy: 0.6733 - val_loss: 3.7713 - val_accuracy: 0.2577\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.7154 - accuracy: 0.6971 - val_loss: 3.7035 - val_accuracy: 0.2485\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.5941 - accuracy: 0.7576 - val_loss: 5.1853 - val_accuracy: 0.2639\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.5784 - accuracy: 0.7665 - val_loss: 5.8041 - val_accuracy: 0.2330\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 0.6345 - accuracy: 0.7271 - val_loss: 5.4548 - val_accuracy: 0.2685\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 0.5977 - accuracy: 0.7643 - val_loss: 5.4937 - val_accuracy: 0.2654\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.5810 - accuracy: 0.7510 - val_loss: 4.5816 - val_accuracy: 0.2654\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.8058 - accuracy: 0.6556 - val_loss: 3.3724 - val_accuracy: 0.2670\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.6703 - accuracy: 0.7224 - val_loss: 5.2123 - val_accuracy: 0.2608\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.6189 - accuracy: 0.7508 - val_loss: 4.9329 - val_accuracy: 0.2593\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.6631 - accuracy: 0.7325 - val_loss: 3.1061 - val_accuracy: 0.2716\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.9250 - accuracy: 0.5994 - val_loss: 3.5650 - val_accuracy: 0.2593\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.6702 - accuracy: 0.7092 - val_loss: 4.2135 - val_accuracy: 0.2716\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 0.5159 - accuracy: 0.7943 - val_loss: 4.2922 - val_accuracy: 0.2870\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.4746 - accuracy: 0.8030 - val_loss: 5.0443 - val_accuracy: 0.2731\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.6592 - accuracy: 0.7325 - val_loss: 4.2547 - val_accuracy: 0.2716\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.5678 - accuracy: 0.7645 - val_loss: 5.5272 - val_accuracy: 0.2855\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 0.4436 - accuracy: 0.8282 - val_loss: 5.6459 - val_accuracy: 0.2670\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.5856 - accuracy: 0.7565 - val_loss: 4.8321 - val_accuracy: 0.2778\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.5213 - accuracy: 0.7922 - val_loss: 4.5137 - val_accuracy: 0.2855\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.4725 - accuracy: 0.8083 - val_loss: 5.8966 - val_accuracy: 0.2670\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.5109 - accuracy: 0.7882 - val_loss: 5.6765 - val_accuracy: 0.2901\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.4505 - accuracy: 0.8117 - val_loss: 5.2289 - val_accuracy: 0.2870\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 0.6186 - accuracy: 0.7475 - val_loss: 5.4262 - val_accuracy: 0.2932\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.4314 - accuracy: 0.8191 - val_loss: 5.2515 - val_accuracy: 0.2670\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 0.4199 - accuracy: 0.8322 - val_loss: 6.0967 - val_accuracy: 0.2778\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.3778 - accuracy: 0.8423 - val_loss: 6.4098 - val_accuracy: 0.2623\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 320ms/step - loss: 0.4567 - accuracy: 0.8092 - val_loss: 5.5182 - val_accuracy: 0.2623\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 318ms/step - loss: 0.6402 - accuracy: 0.7433 - val_loss: 5.9467 - val_accuracy: 0.2716\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.6370 - accuracy: 0.7435 - val_loss: 4.6794 - val_accuracy: 0.2747\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.4434 - accuracy: 0.8143 - val_loss: 5.5296 - val_accuracy: 0.2762\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 0.4211 - accuracy: 0.8226 - val_loss: 8.6074 - val_accuracy: 0.2423\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.1903 - accuracy: 0.5801 - val_loss: 2.6025 - val_accuracy: 0.2469\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.9753 - accuracy: 0.5536 - val_loss: 3.6942 - val_accuracy: 0.2485\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.7088 - accuracy: 0.7105 - val_loss: 3.9103 - val_accuracy: 0.2917\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.5509 - accuracy: 0.7856 - val_loss: 5.0450 - val_accuracy: 0.2531\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 0.4955 - accuracy: 0.7973 - val_loss: 5.5213 - val_accuracy: 0.2731\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.4999 - accuracy: 0.7933 - val_loss: 5.2057 - val_accuracy: 0.2577\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 0.5875 - accuracy: 0.7665 - val_loss: 5.0799 - val_accuracy: 0.2824\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.3923 - accuracy: 0.8380 - val_loss: 5.5561 - val_accuracy: 0.2593\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.3565 - accuracy: 0.8520 - val_loss: 6.5959 - val_accuracy: 0.2639\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.3689 - accuracy: 0.8402 - val_loss: 6.0229 - val_accuracy: 0.2701\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 0.3175 - accuracy: 0.8747 - val_loss: 5.8787 - val_accuracy: 0.3009\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 0.3547 - accuracy: 0.8493 - val_loss: 6.2435 - val_accuracy: 0.2901\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.4013 - accuracy: 0.8422 - val_loss: 6.1767 - val_accuracy: 0.2731\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.9258 - accuracy: 0.6519 - val_loss: 3.6222 - val_accuracy: 0.2515\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 0.6445 - accuracy: 0.7504 - val_loss: 4.8640 - val_accuracy: 0.2762\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.4607 - accuracy: 0.8270 - val_loss: 5.6573 - val_accuracy: 0.2685\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 0.3382 - accuracy: 0.8618 - val_loss: 6.4356 - val_accuracy: 0.2485\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 0.3613 - accuracy: 0.8436 - val_loss: 6.6348 - val_accuracy: 0.2500\n",
            "Processing Fold # 3\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 6s 335ms/step - loss: 1.8327 - accuracy: 0.2037 - val_loss: 6.7454 - val_accuracy: 0.1667\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 2.7356 - accuracy: 0.1998 - val_loss: 1.6072 - val_accuracy: 0.2377\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6087 - accuracy: 0.2357 - val_loss: 1.6064 - val_accuracy: 0.2377\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6082 - accuracy: 0.2322 - val_loss: 1.6057 - val_accuracy: 0.2377\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 5s 324ms/step - loss: 1.6078 - accuracy: 0.2235 - val_loss: 1.6051 - val_accuracy: 0.2377\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6067 - accuracy: 0.2276 - val_loss: 1.6044 - val_accuracy: 0.2377\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6065 - accuracy: 0.2373 - val_loss: 1.6040 - val_accuracy: 0.2377\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6058 - accuracy: 0.2337 - val_loss: 1.6034 - val_accuracy: 0.2377\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6057 - accuracy: 0.2427 - val_loss: 1.6032 - val_accuracy: 0.2377\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6061 - accuracy: 0.2282 - val_loss: 1.6028 - val_accuracy: 0.2377\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6037 - accuracy: 0.2531 - val_loss: 1.6024 - val_accuracy: 0.2377\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6048 - accuracy: 0.2323 - val_loss: 1.6019 - val_accuracy: 0.2377\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6048 - accuracy: 0.2330 - val_loss: 1.6017 - val_accuracy: 0.2377\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 1.6049 - accuracy: 0.2265 - val_loss: 1.6015 - val_accuracy: 0.2377\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6060 - accuracy: 0.2275 - val_loss: 1.6014 - val_accuracy: 0.2377\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6022 - accuracy: 0.2406 - val_loss: 1.6010 - val_accuracy: 0.2377\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6055 - accuracy: 0.2198 - val_loss: 1.6009 - val_accuracy: 0.2377\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6062 - accuracy: 0.2228 - val_loss: 1.6006 - val_accuracy: 0.2377\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6057 - accuracy: 0.2287 - val_loss: 1.6005 - val_accuracy: 0.2377\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6019 - accuracy: 0.2420 - val_loss: 1.6002 - val_accuracy: 0.2377\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6041 - accuracy: 0.2276 - val_loss: 1.6001 - val_accuracy: 0.2377\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6036 - accuracy: 0.2306 - val_loss: 1.5999 - val_accuracy: 0.2377\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6037 - accuracy: 0.2291 - val_loss: 1.5998 - val_accuracy: 0.2377\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6050 - accuracy: 0.2289 - val_loss: 1.5997 - val_accuracy: 0.2377\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6060 - accuracy: 0.2335 - val_loss: 1.5996 - val_accuracy: 0.2377\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6016 - accuracy: 0.2342 - val_loss: 1.5995 - val_accuracy: 0.2377\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6035 - accuracy: 0.2400 - val_loss: 1.5994 - val_accuracy: 0.2377\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6031 - accuracy: 0.2339 - val_loss: 1.5993 - val_accuracy: 0.2377\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6018 - accuracy: 0.2489 - val_loss: 1.5991 - val_accuracy: 0.2377\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6013 - accuracy: 0.2457 - val_loss: 1.5991 - val_accuracy: 0.2377\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6017 - accuracy: 0.2448 - val_loss: 1.5990 - val_accuracy: 0.2377\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6028 - accuracy: 0.2348 - val_loss: 1.5989 - val_accuracy: 0.2377\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5994 - accuracy: 0.2383 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6026 - accuracy: 0.2266 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6020 - accuracy: 0.2385 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6011 - accuracy: 0.2404 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 1.6046 - accuracy: 0.2252 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 5s 323ms/step - loss: 1.6028 - accuracy: 0.2352 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6055 - accuracy: 0.2255 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6012 - accuracy: 0.2399 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6017 - accuracy: 0.2347 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6037 - accuracy: 0.2257 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6026 - accuracy: 0.2422 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6034 - accuracy: 0.2281 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.6020 - accuracy: 0.2424 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.6061 - accuracy: 0.2250 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6010 - accuracy: 0.2429 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.6051 - accuracy: 0.2343 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.5982 - accuracy: 0.2557 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.6057 - accuracy: 0.2323 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.6078 - accuracy: 0.2218 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 52/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.6025 - accuracy: 0.2273 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 53/200\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 1.6027 - accuracy: 0.2259 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 54/200\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.6065 - accuracy: 0.2245 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 55/200\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.6055 - accuracy: 0.2289 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 56/200\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 1.6018 - accuracy: 0.2390 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 57/200\n",
            "16/16 [==============================] - 6s 370ms/step - loss: 1.6044 - accuracy: 0.2320 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 58/200\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 1.5995 - accuracy: 0.2457 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 59/200\n",
            "16/16 [==============================] - 6s 347ms/step - loss: 1.6027 - accuracy: 0.2343 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 60/200\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.6006 - accuracy: 0.2411 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 61/200\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.6029 - accuracy: 0.2326 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 62/200\n",
            "16/16 [==============================] - 6s 349ms/step - loss: 1.6047 - accuracy: 0.2313 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 63/200\n",
            "16/16 [==============================] - 5s 345ms/step - loss: 1.6017 - accuracy: 0.2351 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 64/200\n",
            "16/16 [==============================] - 5s 342ms/step - loss: 1.6018 - accuracy: 0.2415 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 65/200\n",
            "16/16 [==============================] - 5s 346ms/step - loss: 1.6022 - accuracy: 0.2419 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 66/200\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.6035 - accuracy: 0.2325 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 67/200\n",
            "16/16 [==============================] - 5s 345ms/step - loss: 1.6010 - accuracy: 0.2374 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 68/200\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.6039 - accuracy: 0.2321 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 69/200\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 1.6002 - accuracy: 0.2329 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 70/200\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.6013 - accuracy: 0.2404 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 71/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6040 - accuracy: 0.2287 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 72/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6012 - accuracy: 0.2436 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 73/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6030 - accuracy: 0.2361 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 74/200\n",
            "16/16 [==============================] - 5s 343ms/step - loss: 1.6012 - accuracy: 0.2412 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 75/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.6052 - accuracy: 0.2306 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 76/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.6072 - accuracy: 0.2258 - val_loss: 1.5989 - val_accuracy: 0.2377\n",
            "Epoch 77/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.6006 - accuracy: 0.2369 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 78/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.6037 - accuracy: 0.2367 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 79/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6026 - accuracy: 0.2371 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 80/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.5981 - accuracy: 0.2411 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 81/200\n",
            "16/16 [==============================] - 5s 340ms/step - loss: 1.6024 - accuracy: 0.2353 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 82/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6036 - accuracy: 0.2299 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 83/200\n",
            "16/16 [==============================] - 5s 338ms/step - loss: 1.6045 - accuracy: 0.2387 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 84/200\n",
            "16/16 [==============================] - 5s 339ms/step - loss: 1.6015 - accuracy: 0.2381 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 85/200\n",
            "16/16 [==============================] - 5s 341ms/step - loss: 1.5980 - accuracy: 0.2410 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 86/200\n",
            "16/16 [==============================] - 5s 338ms/step - loss: 1.5995 - accuracy: 0.2383 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 87/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6025 - accuracy: 0.2323 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 88/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6010 - accuracy: 0.2466 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 89/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6011 - accuracy: 0.2365 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 90/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6025 - accuracy: 0.2399 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 91/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.6009 - accuracy: 0.2486 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 92/200\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 1.6034 - accuracy: 0.2295 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 93/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6022 - accuracy: 0.2361 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 94/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.5982 - accuracy: 0.2549 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 95/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.6037 - accuracy: 0.2308 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 96/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6029 - accuracy: 0.2360 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 97/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6022 - accuracy: 0.2360 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 98/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6014 - accuracy: 0.2423 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 99/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6042 - accuracy: 0.2286 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 100/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6039 - accuracy: 0.2362 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 101/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6005 - accuracy: 0.2318 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 102/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6033 - accuracy: 0.2343 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 103/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6054 - accuracy: 0.2305 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 104/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6000 - accuracy: 0.2432 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 105/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6049 - accuracy: 0.2276 - val_loss: 1.5989 - val_accuracy: 0.2377\n",
            "Epoch 106/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6018 - accuracy: 0.2316 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 107/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6023 - accuracy: 0.2324 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 108/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6006 - accuracy: 0.2405 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 109/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.5994 - accuracy: 0.2487 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 110/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6043 - accuracy: 0.2334 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 111/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.5995 - accuracy: 0.2512 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 112/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6007 - accuracy: 0.2311 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 113/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6027 - accuracy: 0.2349 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 114/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6032 - accuracy: 0.2395 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 115/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6037 - accuracy: 0.2287 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 116/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.6046 - accuracy: 0.2369 - val_loss: 1.5988 - val_accuracy: 0.2377\n",
            "Epoch 117/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6038 - accuracy: 0.2303 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 118/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6031 - accuracy: 0.2327 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 119/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6024 - accuracy: 0.2328 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 120/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6035 - accuracy: 0.2239 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 121/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6039 - accuracy: 0.2311 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 122/200\n",
            "16/16 [==============================] - 5s 335ms/step - loss: 1.6029 - accuracy: 0.2332 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 123/200\n",
            "16/16 [==============================] - 5s 337ms/step - loss: 1.6017 - accuracy: 0.2435 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 124/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6077 - accuracy: 0.2302 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 125/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6071 - accuracy: 0.2247 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 126/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.5990 - accuracy: 0.2481 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 127/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6034 - accuracy: 0.2320 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 128/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6009 - accuracy: 0.2454 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 129/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6014 - accuracy: 0.2347 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 130/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6006 - accuracy: 0.2370 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 131/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6010 - accuracy: 0.2415 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 132/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6009 - accuracy: 0.2453 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 133/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6040 - accuracy: 0.2230 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 134/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6057 - accuracy: 0.2252 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 135/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.5988 - accuracy: 0.2504 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 136/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6009 - accuracy: 0.2388 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 137/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.5993 - accuracy: 0.2374 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 138/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6053 - accuracy: 0.2268 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 139/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6012 - accuracy: 0.2498 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 140/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.5988 - accuracy: 0.2451 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 141/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6028 - accuracy: 0.2322 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 142/200\n",
            "16/16 [==============================] - 5s 336ms/step - loss: 1.6033 - accuracy: 0.2287 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 143/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6034 - accuracy: 0.2336 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 144/200\n",
            "16/16 [==============================] - 5s 334ms/step - loss: 1.5987 - accuracy: 0.2468 - val_loss: 1.5979 - val_accuracy: 0.2377\n",
            "Epoch 145/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.5998 - accuracy: 0.2420 - val_loss: 1.5979 - val_accuracy: 0.2377\n",
            "Epoch 146/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6016 - accuracy: 0.2427 - val_loss: 1.5979 - val_accuracy: 0.2377\n",
            "Epoch 147/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6037 - accuracy: 0.2391 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 148/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.5979 - accuracy: 0.2514 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 149/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6043 - accuracy: 0.2288 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 150/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6024 - accuracy: 0.2446 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 151/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6056 - accuracy: 0.2254 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 152/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6031 - accuracy: 0.2287 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 153/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6005 - accuracy: 0.2363 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 154/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6009 - accuracy: 0.2482 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 155/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6059 - accuracy: 0.2321 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 156/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6048 - accuracy: 0.2237 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 157/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6024 - accuracy: 0.2421 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 158/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6048 - accuracy: 0.2371 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 159/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.5995 - accuracy: 0.2398 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 160/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6030 - accuracy: 0.2405 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 161/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6035 - accuracy: 0.2382 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 162/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.5967 - accuracy: 0.2484 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 163/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6041 - accuracy: 0.2236 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 164/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6044 - accuracy: 0.2203 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 165/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6028 - accuracy: 0.2402 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 166/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6018 - accuracy: 0.2428 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 167/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6026 - accuracy: 0.2333 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 168/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6014 - accuracy: 0.2453 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 169/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6023 - accuracy: 0.2389 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 170/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6043 - accuracy: 0.2279 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 171/200\n",
            "16/16 [==============================] - 5s 332ms/step - loss: 1.6044 - accuracy: 0.2271 - val_loss: 1.5987 - val_accuracy: 0.2377\n",
            "Epoch 172/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6034 - accuracy: 0.2345 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 173/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.6034 - accuracy: 0.2330 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 174/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6012 - accuracy: 0.2390 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 175/200\n",
            "16/16 [==============================] - 5s 331ms/step - loss: 1.6006 - accuracy: 0.2476 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 176/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6007 - accuracy: 0.2394 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 177/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6027 - accuracy: 0.2339 - val_loss: 1.5986 - val_accuracy: 0.2377\n",
            "Epoch 178/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6004 - accuracy: 0.2438 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 179/200\n",
            "16/16 [==============================] - 5s 333ms/step - loss: 1.6029 - accuracy: 0.2390 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 180/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6007 - accuracy: 0.2430 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 181/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6018 - accuracy: 0.2383 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 182/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6049 - accuracy: 0.2365 - val_loss: 1.5985 - val_accuracy: 0.2377\n",
            "Epoch 183/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5991 - accuracy: 0.2504 - val_loss: 1.5984 - val_accuracy: 0.2377\n",
            "Epoch 184/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6047 - accuracy: 0.2234 - val_loss: 1.5983 - val_accuracy: 0.2377\n",
            "Epoch 185/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6031 - accuracy: 0.2348 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 186/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6025 - accuracy: 0.2387 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 187/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.5980 - accuracy: 0.2475 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 188/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6008 - accuracy: 0.2313 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 189/200\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 1.6012 - accuracy: 0.2411 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 190/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.6039 - accuracy: 0.2338 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 191/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6016 - accuracy: 0.2319 - val_loss: 1.5980 - val_accuracy: 0.2377\n",
            "Epoch 192/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6025 - accuracy: 0.2410 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 193/200\n",
            "16/16 [==============================] - 5s 326ms/step - loss: 1.6041 - accuracy: 0.2421 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 194/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6028 - accuracy: 0.2369 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 195/200\n",
            "16/16 [==============================] - 5s 328ms/step - loss: 1.6040 - accuracy: 0.2390 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 196/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6033 - accuracy: 0.2371 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 197/200\n",
            "16/16 [==============================] - 5s 330ms/step - loss: 1.5993 - accuracy: 0.2453 - val_loss: 1.5981 - val_accuracy: 0.2377\n",
            "Epoch 198/200\n",
            "16/16 [==============================] - 5s 329ms/step - loss: 1.6048 - accuracy: 0.2362 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 199/200\n",
            "16/16 [==============================] - 5s 325ms/step - loss: 1.6045 - accuracy: 0.2354 - val_loss: 1.5982 - val_accuracy: 0.2377\n",
            "Epoch 200/200\n",
            "16/16 [==============================] - 5s 327ms/step - loss: 1.5990 - accuracy: 0.2409 - val_loss: 1.5983 - val_accuracy: 0.2377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGMRLxl8ReWi",
        "outputId": "69668276-867b-41de-c1f4-ee0dd5ba2e28"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 3s 52ms/step - loss: 1.5963 - accuracy: 0.2532\n",
            "test accuracy is : 0.2531791925430298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjPFPPktbgOv"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(100, activation='relu',input_shape=(150*150,)))\n",
        "model.add(layers.Dense(80, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(80, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(40, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m00fSxzNdA26",
        "outputId": "02293aed-4c79-4b70-8654-2548a02cb3fb"
      },
      "source": [
        "history = model.fit(train_images, train_labels, epochs=300, batch_size=128)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 3.7178 - accuracy: 0.2070\n",
            "Epoch 2/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.6909 - accuracy: 0.2172\n",
            "Epoch 3/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.6402 - accuracy: 0.2506\n",
            "Epoch 4/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.6007 - accuracy: 0.2489\n",
            "Epoch 5/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5660 - accuracy: 0.2782\n",
            "Epoch 6/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5572 - accuracy: 0.2926\n",
            "Epoch 7/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5647 - accuracy: 0.2822\n",
            "Epoch 8/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5307 - accuracy: 0.2890\n",
            "Epoch 9/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.5471 - accuracy: 0.2968\n",
            "Epoch 10/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5298 - accuracy: 0.2988\n",
            "Epoch 11/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5415 - accuracy: 0.2848\n",
            "Epoch 12/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5465 - accuracy: 0.3102\n",
            "Epoch 13/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5141 - accuracy: 0.3277\n",
            "Epoch 14/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5381 - accuracy: 0.2988\n",
            "Epoch 15/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.5245 - accuracy: 0.2934\n",
            "Epoch 16/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5136 - accuracy: 0.3055\n",
            "Epoch 17/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.5370 - accuracy: 0.2888\n",
            "Epoch 18/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.5075 - accuracy: 0.3061\n",
            "Epoch 19/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5176 - accuracy: 0.3084\n",
            "Epoch 20/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5293 - accuracy: 0.2950\n",
            "Epoch 21/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.5028 - accuracy: 0.3008\n",
            "Epoch 22/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5252 - accuracy: 0.2806\n",
            "Epoch 23/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4899 - accuracy: 0.3222\n",
            "Epoch 24/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5363 - accuracy: 0.2877\n",
            "Epoch 25/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.4871 - accuracy: 0.3188\n",
            "Epoch 26/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4950 - accuracy: 0.3094\n",
            "Epoch 27/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4901 - accuracy: 0.3174\n",
            "Epoch 28/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4784 - accuracy: 0.3134\n",
            "Epoch 29/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4711 - accuracy: 0.3229\n",
            "Epoch 30/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4963 - accuracy: 0.3019\n",
            "Epoch 31/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.5105 - accuracy: 0.3040\n",
            "Epoch 32/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4701 - accuracy: 0.3284\n",
            "Epoch 33/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4989 - accuracy: 0.3239\n",
            "Epoch 34/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4755 - accuracy: 0.3294\n",
            "Epoch 35/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4804 - accuracy: 0.3415\n",
            "Epoch 36/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4769 - accuracy: 0.3177\n",
            "Epoch 37/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4718 - accuracy: 0.3392\n",
            "Epoch 38/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4580 - accuracy: 0.3513\n",
            "Epoch 39/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4534 - accuracy: 0.3294\n",
            "Epoch 40/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4576 - accuracy: 0.3478\n",
            "Epoch 41/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.4645 - accuracy: 0.3357\n",
            "Epoch 42/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4345 - accuracy: 0.3335\n",
            "Epoch 43/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4138 - accuracy: 0.3427\n",
            "Epoch 44/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.5202 - accuracy: 0.3462\n",
            "Epoch 45/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4665 - accuracy: 0.3305\n",
            "Epoch 46/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.4546 - accuracy: 0.3349\n",
            "Epoch 47/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4273 - accuracy: 0.3392\n",
            "Epoch 48/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4418 - accuracy: 0.3422\n",
            "Epoch 49/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.4370 - accuracy: 0.3651\n",
            "Epoch 50/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.4359 - accuracy: 0.3300\n",
            "Epoch 51/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.4122 - accuracy: 0.3420\n",
            "Epoch 52/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4039 - accuracy: 0.3709\n",
            "Epoch 53/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.4310 - accuracy: 0.3505\n",
            "Epoch 54/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4120 - accuracy: 0.3810\n",
            "Epoch 55/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3821 - accuracy: 0.3747\n",
            "Epoch 56/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.4726 - accuracy: 0.3416\n",
            "Epoch 57/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3855 - accuracy: 0.3719\n",
            "Epoch 58/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4045 - accuracy: 0.3787\n",
            "Epoch 59/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4071 - accuracy: 0.3574\n",
            "Epoch 60/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3919 - accuracy: 0.3797\n",
            "Epoch 61/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3982 - accuracy: 0.3717\n",
            "Epoch 62/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3995 - accuracy: 0.3489\n",
            "Epoch 63/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4218 - accuracy: 0.3532\n",
            "Epoch 64/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3562 - accuracy: 0.3849\n",
            "Epoch 65/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3869 - accuracy: 0.3668\n",
            "Epoch 66/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4014 - accuracy: 0.3518\n",
            "Epoch 67/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3588 - accuracy: 0.3749\n",
            "Epoch 68/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.4521 - accuracy: 0.3529\n",
            "Epoch 69/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4022 - accuracy: 0.3790\n",
            "Epoch 70/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3940 - accuracy: 0.3712\n",
            "Epoch 71/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4339 - accuracy: 0.3528\n",
            "Epoch 72/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4011 - accuracy: 0.3622\n",
            "Epoch 73/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4069 - accuracy: 0.3499\n",
            "Epoch 74/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3639 - accuracy: 0.3833\n",
            "Epoch 75/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3852 - accuracy: 0.3733\n",
            "Epoch 76/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3775 - accuracy: 0.3724\n",
            "Epoch 77/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3357 - accuracy: 0.4088\n",
            "Epoch 78/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.4269 - accuracy: 0.3473\n",
            "Epoch 79/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3537 - accuracy: 0.3884\n",
            "Epoch 80/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3860 - accuracy: 0.3627\n",
            "Epoch 81/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3363 - accuracy: 0.4077\n",
            "Epoch 82/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3535 - accuracy: 0.3907\n",
            "Epoch 83/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.3604 - accuracy: 0.3949\n",
            "Epoch 84/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3029 - accuracy: 0.4211\n",
            "Epoch 85/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3410 - accuracy: 0.4068\n",
            "Epoch 86/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3374 - accuracy: 0.4217\n",
            "Epoch 87/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3580 - accuracy: 0.3997\n",
            "Epoch 88/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.4028 - accuracy: 0.3801\n",
            "Epoch 89/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3120 - accuracy: 0.4283\n",
            "Epoch 90/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3788 - accuracy: 0.4056\n",
            "Epoch 91/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3065 - accuracy: 0.4205\n",
            "Epoch 92/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3146 - accuracy: 0.4231\n",
            "Epoch 93/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3765 - accuracy: 0.3891\n",
            "Epoch 94/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3243 - accuracy: 0.4161\n",
            "Epoch 95/300\n",
            "21/21 [==============================] - 1s 48ms/step - loss: 1.3631 - accuracy: 0.3794\n",
            "Epoch 96/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2970 - accuracy: 0.4238\n",
            "Epoch 97/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.5010 - accuracy: 0.3852\n",
            "Epoch 98/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3088 - accuracy: 0.4248\n",
            "Epoch 99/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.5059 - accuracy: 0.3778\n",
            "Epoch 100/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.3556 - accuracy: 0.3913\n",
            "Epoch 101/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3144 - accuracy: 0.4163\n",
            "Epoch 102/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3174 - accuracy: 0.4190\n",
            "Epoch 103/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3382 - accuracy: 0.3975\n",
            "Epoch 104/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3119 - accuracy: 0.4288\n",
            "Epoch 105/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2966 - accuracy: 0.4202\n",
            "Epoch 106/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2928 - accuracy: 0.4296\n",
            "Epoch 107/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.3520 - accuracy: 0.4004\n",
            "Epoch 108/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3745 - accuracy: 0.3930\n",
            "Epoch 109/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3104 - accuracy: 0.4350\n",
            "Epoch 110/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2437 - accuracy: 0.4489\n",
            "Epoch 111/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3030 - accuracy: 0.4154\n",
            "Epoch 112/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3054 - accuracy: 0.4146\n",
            "Epoch 113/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3436 - accuracy: 0.3983\n",
            "Epoch 114/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3224 - accuracy: 0.4166\n",
            "Epoch 115/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2942 - accuracy: 0.4279\n",
            "Epoch 116/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.4202 - accuracy: 0.3709\n",
            "Epoch 117/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2866 - accuracy: 0.4188\n",
            "Epoch 118/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2932 - accuracy: 0.4265\n",
            "Epoch 119/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2736 - accuracy: 0.4251\n",
            "Epoch 120/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2308 - accuracy: 0.4624\n",
            "Epoch 121/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2887 - accuracy: 0.4388\n",
            "Epoch 122/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3544 - accuracy: 0.3919\n",
            "Epoch 123/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.3792 - accuracy: 0.4176\n",
            "Epoch 124/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2348 - accuracy: 0.4494\n",
            "Epoch 125/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3047 - accuracy: 0.4196\n",
            "Epoch 126/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.3005 - accuracy: 0.4237\n",
            "Epoch 127/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3131 - accuracy: 0.4170\n",
            "Epoch 128/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2430 - accuracy: 0.4528\n",
            "Epoch 129/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3785 - accuracy: 0.4246\n",
            "Epoch 130/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2421 - accuracy: 0.4430\n",
            "Epoch 131/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2199 - accuracy: 0.4667\n",
            "Epoch 132/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2358 - accuracy: 0.4455\n",
            "Epoch 133/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3122 - accuracy: 0.4422\n",
            "Epoch 134/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.3073 - accuracy: 0.4180\n",
            "Epoch 135/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3376 - accuracy: 0.4337\n",
            "Epoch 136/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.1998 - accuracy: 0.4699\n",
            "Epoch 137/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.3027 - accuracy: 0.4349\n",
            "Epoch 138/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2962 - accuracy: 0.4302\n",
            "Epoch 139/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2829 - accuracy: 0.4275\n",
            "Epoch 140/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3845 - accuracy: 0.4243\n",
            "Epoch 141/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3728 - accuracy: 0.4162\n",
            "Epoch 142/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2006 - accuracy: 0.4827\n",
            "Epoch 143/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2748 - accuracy: 0.4381\n",
            "Epoch 144/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3071 - accuracy: 0.4232\n",
            "Epoch 145/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2384 - accuracy: 0.4446\n",
            "Epoch 146/300\n",
            "21/21 [==============================] - 1s 49ms/step - loss: 1.2719 - accuracy: 0.4296\n",
            "Epoch 147/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2608 - accuracy: 0.4385\n",
            "Epoch 148/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2351 - accuracy: 0.4617\n",
            "Epoch 149/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2003 - accuracy: 0.4743\n",
            "Epoch 150/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2850 - accuracy: 0.4378\n",
            "Epoch 151/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2619 - accuracy: 0.4550\n",
            "Epoch 152/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.3225 - accuracy: 0.4104\n",
            "Epoch 153/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2687 - accuracy: 0.4327\n",
            "Epoch 154/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3276 - accuracy: 0.3971\n",
            "Epoch 155/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2343 - accuracy: 0.4716\n",
            "Epoch 156/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3215 - accuracy: 0.4358\n",
            "Epoch 157/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2365 - accuracy: 0.4588\n",
            "Epoch 158/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.1298 - accuracy: 0.5140\n",
            "Epoch 159/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.3755 - accuracy: 0.4079\n",
            "Epoch 160/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.2367 - accuracy: 0.4440\n",
            "Epoch 161/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2086 - accuracy: 0.4883\n",
            "Epoch 162/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1751 - accuracy: 0.4857\n",
            "Epoch 163/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2710 - accuracy: 0.4222\n",
            "Epoch 164/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2967 - accuracy: 0.4563\n",
            "Epoch 165/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2894 - accuracy: 0.4531\n",
            "Epoch 166/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.1757 - accuracy: 0.4837\n",
            "Epoch 167/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2827 - accuracy: 0.4251\n",
            "Epoch 168/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2447 - accuracy: 0.4671\n",
            "Epoch 169/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2556 - accuracy: 0.4849\n",
            "Epoch 170/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2898 - accuracy: 0.4307\n",
            "Epoch 171/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2111 - accuracy: 0.4582\n",
            "Epoch 172/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2504 - accuracy: 0.4713\n",
            "Epoch 173/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.1891 - accuracy: 0.4629\n",
            "Epoch 174/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2352 - accuracy: 0.4479\n",
            "Epoch 175/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2541 - accuracy: 0.4545\n",
            "Epoch 176/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2197 - accuracy: 0.4483\n",
            "Epoch 177/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2628 - accuracy: 0.4511\n",
            "Epoch 178/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2745 - accuracy: 0.4383\n",
            "Epoch 179/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.3049 - accuracy: 0.4413\n",
            "Epoch 180/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3238 - accuracy: 0.4334\n",
            "Epoch 181/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1881 - accuracy: 0.4887\n",
            "Epoch 182/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2355 - accuracy: 0.4612\n",
            "Epoch 183/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2766 - accuracy: 0.4548\n",
            "Epoch 184/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2382 - accuracy: 0.4643\n",
            "Epoch 185/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.2791 - accuracy: 0.4253\n",
            "Epoch 186/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.1888 - accuracy: 0.4795\n",
            "Epoch 187/300\n",
            "21/21 [==============================] - 1s 51ms/step - loss: 1.1795 - accuracy: 0.4882\n",
            "Epoch 188/300\n",
            "21/21 [==============================] - 1s 50ms/step - loss: 1.1382 - accuracy: 0.5062\n",
            "Epoch 189/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2174 - accuracy: 0.4759\n",
            "Epoch 190/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.1613 - accuracy: 0.4988\n",
            "Epoch 191/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1818 - accuracy: 0.4890\n",
            "Epoch 192/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.2544 - accuracy: 0.4731\n",
            "Epoch 193/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.1629 - accuracy: 0.5030\n",
            "Epoch 194/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.5000 - accuracy: 0.4424\n",
            "Epoch 195/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.1487 - accuracy: 0.5078\n",
            "Epoch 196/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.2128 - accuracy: 0.4764\n",
            "Epoch 197/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.3497 - accuracy: 0.4400\n",
            "Epoch 198/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.1157 - accuracy: 0.5232\n",
            "Epoch 199/300\n",
            "21/21 [==============================] - 1s 52ms/step - loss: 1.2181 - accuracy: 0.4677\n",
            "Epoch 200/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.1347 - accuracy: 0.5160\n",
            "Epoch 201/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.2249 - accuracy: 0.4739\n",
            "Epoch 202/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1811 - accuracy: 0.4914\n",
            "Epoch 203/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1879 - accuracy: 0.4873\n",
            "Epoch 204/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2088 - accuracy: 0.4713\n",
            "Epoch 205/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2459 - accuracy: 0.4688\n",
            "Epoch 206/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1764 - accuracy: 0.4857\n",
            "Epoch 207/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1651 - accuracy: 0.4803\n",
            "Epoch 208/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.5232 - accuracy: 0.4455\n",
            "Epoch 209/300\n",
            "21/21 [==============================] - 1s 53ms/step - loss: 1.1664 - accuracy: 0.4756\n",
            "Epoch 210/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1591 - accuracy: 0.5035\n",
            "Epoch 211/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1662 - accuracy: 0.4973\n",
            "Epoch 212/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.3190 - accuracy: 0.4677\n",
            "Epoch 213/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1001 - accuracy: 0.5196\n",
            "Epoch 214/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2186 - accuracy: 0.4729\n",
            "Epoch 215/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1333 - accuracy: 0.5113\n",
            "Epoch 216/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1566 - accuracy: 0.5013\n",
            "Epoch 217/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.2148 - accuracy: 0.4808\n",
            "Epoch 218/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1609 - accuracy: 0.5175\n",
            "Epoch 219/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1573 - accuracy: 0.5069\n",
            "Epoch 220/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1623 - accuracy: 0.5046\n",
            "Epoch 221/300\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.1830 - accuracy: 0.4798\n",
            "Epoch 222/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.1435 - accuracy: 0.5090\n",
            "Epoch 223/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.2192 - accuracy: 0.4635\n",
            "Epoch 224/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.2080 - accuracy: 0.4901\n",
            "Epoch 225/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.1912 - accuracy: 0.4770\n",
            "Epoch 226/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1718 - accuracy: 0.4748\n",
            "Epoch 227/300\n",
            "21/21 [==============================] - 1s 61ms/step - loss: 1.1730 - accuracy: 0.4743\n",
            "Epoch 228/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.2210 - accuracy: 0.4658\n",
            "Epoch 229/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.1138 - accuracy: 0.5146\n",
            "Epoch 230/300\n",
            "21/21 [==============================] - 1s 64ms/step - loss: 1.1598 - accuracy: 0.4940\n",
            "Epoch 231/300\n",
            "21/21 [==============================] - 1s 62ms/step - loss: 1.2870 - accuracy: 0.4563\n",
            "Epoch 232/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.2328 - accuracy: 0.4495\n",
            "Epoch 233/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.1741 - accuracy: 0.4845\n",
            "Epoch 234/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.1550 - accuracy: 0.5045\n",
            "Epoch 235/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.1614 - accuracy: 0.4896\n",
            "Epoch 236/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.3950 - accuracy: 0.4743\n",
            "Epoch 237/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.1363 - accuracy: 0.5003\n",
            "Epoch 238/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1263 - accuracy: 0.5098\n",
            "Epoch 239/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.0859 - accuracy: 0.5417\n",
            "Epoch 240/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.1928 - accuracy: 0.4804\n",
            "Epoch 241/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.2127 - accuracy: 0.4818\n",
            "Epoch 242/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1666 - accuracy: 0.4837\n",
            "Epoch 243/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.1729 - accuracy: 0.4821\n",
            "Epoch 244/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1796 - accuracy: 0.4907\n",
            "Epoch 245/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.3463 - accuracy: 0.4391\n",
            "Epoch 246/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1576 - accuracy: 0.4881\n",
            "Epoch 247/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1949 - accuracy: 0.4922\n",
            "Epoch 248/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1928 - accuracy: 0.4683\n",
            "Epoch 249/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.2502 - accuracy: 0.4871\n",
            "Epoch 250/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.0705 - accuracy: 0.5467\n",
            "Epoch 251/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1741 - accuracy: 0.4828\n",
            "Epoch 252/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1393 - accuracy: 0.5082\n",
            "Epoch 253/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1471 - accuracy: 0.5021\n",
            "Epoch 254/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1656 - accuracy: 0.4907\n",
            "Epoch 255/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1825 - accuracy: 0.4734\n",
            "Epoch 256/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.2776 - accuracy: 0.4958\n",
            "Epoch 257/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1699 - accuracy: 0.5003\n",
            "Epoch 258/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.3252 - accuracy: 0.4478\n",
            "Epoch 259/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1277 - accuracy: 0.5223\n",
            "Epoch 260/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1585 - accuracy: 0.4992\n",
            "Epoch 261/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.4115 - accuracy: 0.4331\n",
            "Epoch 262/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.0968 - accuracy: 0.5499\n",
            "Epoch 263/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1387 - accuracy: 0.5024\n",
            "Epoch 264/300\n",
            "21/21 [==============================] - 1s 70ms/step - loss: 1.1896 - accuracy: 0.5154\n",
            "Epoch 265/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1209 - accuracy: 0.5238\n",
            "Epoch 266/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1021 - accuracy: 0.5366\n",
            "Epoch 267/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1763 - accuracy: 0.4908\n",
            "Epoch 268/300\n",
            "21/21 [==============================] - 1s 54ms/step - loss: 1.0810 - accuracy: 0.5366\n",
            "Epoch 269/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.1028 - accuracy: 0.5301\n",
            "Epoch 270/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1128 - accuracy: 0.5166\n",
            "Epoch 271/300\n",
            "21/21 [==============================] - 1s 68ms/step - loss: 1.3378 - accuracy: 0.4928\n",
            "Epoch 272/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1271 - accuracy: 0.5026\n",
            "Epoch 273/300\n",
            "21/21 [==============================] - 1s 67ms/step - loss: 1.1841 - accuracy: 0.5010\n",
            "Epoch 274/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.0630 - accuracy: 0.5544\n",
            "Epoch 275/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.2007 - accuracy: 0.4896\n",
            "Epoch 276/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.0724 - accuracy: 0.5540\n",
            "Epoch 277/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.0973 - accuracy: 0.5319\n",
            "Epoch 278/300\n",
            "21/21 [==============================] - 1s 64ms/step - loss: 1.1035 - accuracy: 0.5226\n",
            "Epoch 279/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.1342 - accuracy: 0.5343\n",
            "Epoch 280/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.0939 - accuracy: 0.5384\n",
            "Epoch 281/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.0320 - accuracy: 0.5530\n",
            "Epoch 282/300\n",
            "21/21 [==============================] - 1s 60ms/step - loss: 1.2810 - accuracy: 0.4880\n",
            "Epoch 283/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.0503 - accuracy: 0.5433\n",
            "Epoch 284/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.0660 - accuracy: 0.5354\n",
            "Epoch 285/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1342 - accuracy: 0.5071\n",
            "Epoch 286/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1183 - accuracy: 0.5254\n",
            "Epoch 287/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.0160 - accuracy: 0.5725\n",
            "Epoch 288/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1802 - accuracy: 0.5047\n",
            "Epoch 289/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.0921 - accuracy: 0.5206\n",
            "Epoch 290/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1631 - accuracy: 0.4898\n",
            "Epoch 291/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.1228 - accuracy: 0.5317\n",
            "Epoch 292/300\n",
            "21/21 [==============================] - 1s 58ms/step - loss: 1.1570 - accuracy: 0.5034\n",
            "Epoch 293/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.2473 - accuracy: 0.4703\n",
            "Epoch 294/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.0584 - accuracy: 0.5520\n",
            "Epoch 295/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.0459 - accuracy: 0.5560\n",
            "Epoch 296/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.1072 - accuracy: 0.5312\n",
            "Epoch 297/300\n",
            "21/21 [==============================] - 1s 57ms/step - loss: 1.1418 - accuracy: 0.5221\n",
            "Epoch 298/300\n",
            "21/21 [==============================] - 1s 56ms/step - loss: 1.0948 - accuracy: 0.5360\n",
            "Epoch 299/300\n",
            "21/21 [==============================] - 1s 55ms/step - loss: 1.0333 - accuracy: 0.5761\n",
            "Epoch 300/300\n",
            "21/21 [==============================] - 1s 59ms/step - loss: 1.3684 - accuracy: 0.4930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FROO2LUsdlIn",
        "outputId": "61c33409-cfed-4635-86cd-a9db42101151"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images,test_labels)\n",
        "print(\"test accuracy is :\", test_accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 1s 6ms/step - loss: 2.4423 - accuracy: 0.2994\n",
            "test accuracy is : 0.2994219660758972\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}